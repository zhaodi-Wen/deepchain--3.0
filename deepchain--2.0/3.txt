1 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Traceback (most recent call last):
  File "./run_mnist.py", line 158, in <module>
    n_iter=n_iter, print_after=print_after
TypeError: momentum1() got an unexpected keyword argument 'worker_num'
2 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Traceback (most recent call last):
  File "./run_mnist.py", line 158, in <module>
    n_iter=n_iter, print_after=print_after
TypeError: momentum1() got an unexpected keyword argument 'worker_num'
3 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)


Experimenting on sgd3

Experiment-1
Traceback (most recent call last):
  File "./run_mnist.py", line 158, in <module>
    n_iter=n_iter, print_after=print_after
TypeError: momentum1() got an unexpected keyword argument 'worker_num'
4 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
^CTraceback (most recent call last):
  File "./run_mnist.py", line 9, in <module>
    from hipsternet.split_mnist import Split_data
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py", line 8, in <module>
    mnist = input_data.read_data_sets("MNIST_Data/",one_hot=True)
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 250, in new_func
    return func(*args, **kwargs)
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py", line 262, in read_data_sets
    train_images = extract_images(f)
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 250, in new_func
    return func(*args, **kwargs)
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py", line 69, in extract_images
    buf = bytestream.read(rows * cols * num_images)
  File "/home/wzd/anaconda3/lib/python3.6/gzip.py", line 276, in read
    return self._buffer.read(size)
  File "/home/wzd/anaconda3/lib/python3.6/_compression.py", line 68, in readinto
    data = self.read(len(byte_view))
  File "/home/wzd/anaconda3/lib/python3.6/gzip.py", line 471, in read
    uncompress = self._decompressor.decompress(buf, size)
KeyboardInterrupt

wzd@wzd-X455LJ:~/桌面/deepchain2/deepchain/deepchain$ ./run.sh
1 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Traceback (most recent call last):
  File "./run_mnist.py", line 158, in <module>
    n_iter=n_iter, print_after=print_after
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 186, in momentum1
    velocity = {k: np.zeros_like(v) for k, v in nn.model.items()}
AttributeError: 'list' object has no attribute 'model'
2 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
^CTraceback (most recent call last):
  File "./run_mnist.py", line 8, in <module>
    from tensorflow.examples.tutorials.mnist import input_data
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/examples/tutorials/mnist/__init__.py", line 21, in <module>
    from tensorflow.examples.tutorials.mnist import input_data
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/examples/tutorials/mnist/input_data.py", line 30, in <module>
    from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/__init__.py", line 37, in <module>
    from tensorflow.contrib import distributions
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/distributions/__init__.py", line 39, in <module>
    from tensorflow.contrib.distributions.python.ops.estimator import *
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/estimator.py", line 21, in <module>
    from tensorflow.contrib.learn.python.learn.estimators.head import _compute_weighted_loss
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/__init__.py", line 95, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/__init__.py", line 28, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/__init__.py", line 28, in <module>
    from tensorflow.contrib.learn.python.learn import basic_session_run_hooks
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/basic_session_run_hooks.py", line 37, in <module>
    basic_session_run_hooks.StopAtStepHook)
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 147, in deprecated_alias
    class NewClass(func_or_class):  # pylint: disable=missing-docstring
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 154, in NewClass
    __module__ = _call_location(outer=True)
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 73, in _call_location
    frame = tf_inspect.currentframe()
  File "/home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py", line 39, in currentframe
    return _inspect.stack()[1][0]
  File "/home/wzd/anaconda3/lib/python3.6/inspect.py", line 1494, in stack
    return getouterframes(sys._getframe(1), context)
  File "/home/wzd/anaconda3/lib/python3.6/inspect.py", line 1471, in getouterframes
    frameinfo = (frame,) + getframeinfo(frame, context)
  File "/home/wzd/anaconda3/lib/python3.6/inspect.py", line 1445, in getframeinfo
    lines, lnum = findsource(frame)
  File "/home/wzd/anaconda3/lib/python3.6/inspect.py", line 768, in findsource
    file = getsourcefile(object)
  File "/home/wzd/anaconda3/lib/python3.6/inspect.py", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File "/home/wzd/anaconda3/lib/python3.6/inspect.py", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
KeyboardInterrupt

wzd@wzd-X455LJ:~/桌面/deepchain2/deepchain/deepchain$ ./run.sh
1 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 0.8128 validation: 0.919800
Iter-50 loss: 1.0247 validation: 0.932200
Iter-50 loss: 0.8504 validation: 0.922800
Iter-50 loss: 0.9358 validation: 0.938000
Iter-100 loss: 0.9801 validation: 0.951600
Iter-100 loss: 0.9995 validation: 0.934600
Iter-100 loss: 0.9110 validation: 0.945600
Iter-100 loss: 1.0498 validation: 0.956200
Iter-150 loss: 1.1368 validation: 0.955200
Iter-150 loss: 0.8941 validation: 0.968200
Iter-150 loss: 0.9764 validation: 0.954400
Iter-150 loss: 0.8650 validation: 0.960800
Iter-200 loss: 0.9584 validation: 0.960600
Iter-200 loss: 0.9643 validation: 0.965800
Iter-200 loss: 0.8723 validation: 0.960800
Iter-200 loss: 0.8722 validation: 0.956200
Iter-250 loss: 0.9513 validation: 0.966600
Iter-250 loss: 0.8513 validation: 0.969600
Iter-250 loss: 0.8692 validation: 0.962000
Iter-250 loss: 0.8598 validation: 0.973800
Iter-300 loss: 1.0758 validation: 0.974200
Iter-300 loss: 0.8675 validation: 0.970600
Iter-300 loss: 0.8819 validation: 0.965800
Iter-300 loss: 0.8924 validation: 0.971800
Iter-350 loss: 0.8857 validation: 0.972800
Iter-350 loss: 0.8934 validation: 0.975400
Iter-350 loss: 0.8782 validation: 0.960800
Iter-350 loss: 0.9749 validation: 0.967200
Iter-400 loss: 0.9238 validation: 0.971800
Iter-400 loss: 0.9839 validation: 0.962400
Iter-400 loss: 0.8877 validation: 0.964400
Iter-400 loss: 0.8888 validation: 0.969800
Iter-450 loss: 1.0102 validation: 0.975400
Iter-450 loss: 0.9297 validation: 0.975000
Iter-450 loss: 1.0753 validation: 0.976200
Iter-450 loss: 0.9223 validation: 0.978800
Iter-500 loss: 0.9095 validation: 0.975400
Iter-500 loss: 0.9297 validation: 0.972400
Iter-500 loss: 0.9079 validation: 0.968400
Iter-500 loss: 0.9255 validation: 0.974600
Iter-550 loss: 0.9191 validation: 0.979000
Iter-550 loss: 0.9224 validation: 0.979400
Iter-550 loss: 0.9090 validation: 0.977800
Iter-550 loss: 0.9027 validation: 0.975200
Iter-600 loss: 0.9156 validation: 0.973600
Iter-600 loss: 0.9686 validation: 0.974200
Iter-600 loss: 0.9202 validation: 0.976600
Iter-600 loss: 0.9168 validation: 0.972000
Iter-650 loss: 0.9645 validation: 0.978200
Iter-650 loss: 0.9306 validation: 0.978600
Iter-650 loss: 0.9382 validation: 0.973600
Iter-650 loss: 1.0627 validation: 0.977600
Iter-700 loss: 0.9433 validation: 0.979000
Iter-700 loss: 0.9857 validation: 0.978000
Iter-700 loss: 0.9462 validation: 0.976600
Iter-700 loss: 0.9286 validation: 0.981000
Iter-750 loss: 0.9703 validation: 0.981000
Iter-750 loss: 0.9610 validation: 0.981600
Iter-750 loss: 0.9344 validation: 0.978600
Iter-750 loss: 0.9263 validation: 0.979000
Iter-800 loss: 0.9524 validation: 0.978200
Iter-800 loss: 0.9363 validation: 0.982400
Iter-800 loss: 0.9785 validation: 0.975200
Iter-800 loss: 0.9335 validation: 0.973000
Iter-850 loss: 0.9609 validation: 0.980000
Iter-850 loss: 0.9426 validation: 0.980000
Iter-850 loss: 0.9391 validation: 0.976600
Iter-850 loss: 0.9378 validation: 0.978800
Iter-900 loss: 0.9955 validation: 0.976800
Iter-900 loss: 0.9486 validation: 0.981400
Iter-900 loss: 0.9559 validation: 0.976800
Iter-900 loss: 0.9443 validation: 0.980200
Iter-950 loss: 0.9572 validation: 0.980800
Iter-950 loss: 0.9945 validation: 0.982200
Iter-950 loss: 0.9517 validation: 0.976400
Iter-950 loss: 0.9494 validation: 0.980000
Iter-1000 loss: 0.9574 validation: 0.968200
Iter-1000 loss: 0.9619 validation: 0.978800
Iter-1000 loss: 1.0047 validation: 0.975400
Iter-1000 loss: 0.9555 validation: 0.976200
Iter-1050 loss: 0.9758 validation: 0.979600
Iter-1050 loss: 0.9739 validation: 0.979000
Iter-1050 loss: 0.9616 validation: 0.976000
Iter-1050 loss: 0.9545 validation: 0.978000
Iter-1100 loss: 0.9655 validation: 0.980600
Iter-1100 loss: 0.9781 validation: 0.980400
Iter-1100 loss: 0.9664 validation: 0.976400
Iter-1100 loss: 0.9562 validation: 0.980200
Iter-1150 loss: 0.9703 validation: 0.980800
Iter-1150 loss: 1.0086 validation: 0.980600
Iter-1150 loss: 0.9774 validation: 0.975800
Iter-1150 loss: 0.9616 validation: 0.981000
Iter-1200 loss: 0.9755 validation: 0.979000
Iter-1200 loss: 0.9721 validation: 0.979400
Iter-1200 loss: 0.9691 validation: 0.978400
Iter-1200 loss: 0.9654 validation: 0.979800
Iter-1250 loss: 0.9784 validation: 0.980600
Iter-1250 loss: 0.9880 validation: 0.984000
Iter-1250 loss: 0.9723 validation: 0.976800
Iter-1250 loss: 0.9649 validation: 0.980400
Iter-1300 loss: 0.9801 validation: 0.982200
Iter-1300 loss: 0.9780 validation: 0.978000
Iter-1300 loss: 0.9752 validation: 0.976200
Iter-1300 loss: 0.9729 validation: 0.980400
Iter-1350 loss: 0.9806 validation: 0.983200
Iter-1350 loss: 0.9821 validation: 0.980000
Iter-1350 loss: 0.9843 validation: 0.980400
Iter-1350 loss: 0.9786 validation: 0.979400
Iter-1400 loss: 0.9824 validation: 0.982200
Iter-1400 loss: 0.9802 validation: 0.980800
Iter-1400 loss: 0.9815 validation: 0.981000
Iter-1400 loss: 1.0093 validation: 0.979800
Iter-1450 loss: 0.9970 validation: 0.981400
Iter-1450 loss: 0.9829 validation: 0.982200
Iter-1450 loss: 0.9824 validation: 0.979600
Iter-1450 loss: 0.9756 validation: 0.980200
Iter-1500 loss: 0.9869 validation: 0.982400
Iter-1500 loss: 0.9854 validation: 0.981600
Iter-1500 loss: 0.9847 validation: 0.980000
Iter-1500 loss: 0.9749 validation: 0.979400
Mean accuracy 1: 0.9805, std: 0.0000
Mean accuracy 2: 0.9822, std: 0.0000
Mean accuracy 3: 0.9791, std: 0.0000
Mean accuracy 4: 0.9823, std: 0.0000
Iter-50 loss: 1.3505 validation: 0.903200
Iter-100 loss: 1.0179 validation: 0.951200
Iter-150 loss: 1.2379 validation: 0.960600
Iter-200 loss: 1.0778 validation: 0.970000
Iter-250 loss: 1.0455 validation: 0.963000
Iter-300 loss: 1.1162 validation: 0.972600
Iter-350 loss: 1.0579 validation: 0.970600
Iter-400 loss: 1.1338 validation: 0.971200
Iter-450 loss: 1.0908 validation: 0.979600
Iter-500 loss: 1.0798 validation: 0.979200
Iter-550 loss: 1.0746 validation: 0.978600
Iter-600 loss: 1.1204 validation: 0.971800
Iter-650 loss: 1.1371 validation: 0.981200
Iter-700 loss: 1.1109 validation: 0.979200
Iter-750 loss: 1.0999 validation: 0.981800
Iter-800 loss: 1.1054 validation: 0.979200
Iter-850 loss: 1.1722 validation: 0.980000
Iter-900 loss: 1.1249 validation: 0.984400
Iter-950 loss: 1.3213 validation: 0.982800
Iter-1000 loss: 1.1425 validation: 0.981800
Iter-1050 loss: 1.1415 validation: 0.979400
Iter-1100 loss: 1.1609 validation: 0.982600
Iter-1150 loss: 1.1535 validation: 0.980200
^CTraceback (most recent call last):
  File "./run_mnist.py", line 171, in <module>
    n_iter = n_iter,print_after = print_after
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 168, in momentum
    grad, loss = nn.train_step(X_mini, y_mini)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/neuralnet.py", line 69, in train_step
    grad = self.backward(y_pred, y_train, cache)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/neuralnet.py", line 617, in backward
    dX, dW1, db1 = l.conv_backward(dh1, h1_cache)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py", line 230, in conv_backward
    dX = col2im_indices(dX_col, X.shape, h_filter, w_filter, padding=padding, stride=stride)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/im2col.py", line 50, in col2im_indices
    np.add.at(x_padded, (slice(None), k, i, j), cols_reshaped)
KeyboardInterrupt

wzd@wzd-X455LJ:~/桌面/deepchain2/deepchain/deepchain$ ./run.sh
1 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.0000 validation: 0.915600
Iter-50 loss: 1.1659 validation: 0.933400
Iter-50 loss: 0.8177 validation: 0.923200
Iter-50 loss: 1.0317 validation: 0.883800
Iter-100 loss: 1.1644 validation: 0.950200
Iter-100 loss: 0.9973 validation: 0.957000
Iter-100 loss: 0.9428 validation: 0.942000
Iter-100 loss: 0.9383 validation: 0.939600
Iter-150 loss: 0.9558 validation: 0.948600
Iter-150 loss: 0.8844 validation: 0.968000
Iter-150 loss: 0.8819 validation: 0.965000
Iter-150 loss: 0.9914 validation: 0.943200
Iter-200 loss: 0.8703 validation: 0.954600
Iter-200 loss: 1.0287 validation: 0.966000
Iter-200 loss: 0.9256 validation: 0.969400
Iter-200 loss: 0.9012 validation: 0.956800
Iter-250 loss: 0.9508 validation: 0.971600
Iter-250 loss: 0.9131 validation: 0.965600
Iter-250 loss: 0.8659 validation: 0.970600
Iter-250 loss: 0.9906 validation: 0.961400
Iter-300 loss: 0.8694 validation: 0.972400
Iter-300 loss: 0.9432 validation: 0.971000
Iter-300 loss: 0.8905 validation: 0.974600
Iter-300 loss: 0.9594 validation: 0.971000
Iter-350 loss: 0.8878 validation: 0.962400
Iter-350 loss: 0.9494 validation: 0.972400
Iter-350 loss: 0.8998 validation: 0.978200
Iter-350 loss: 0.9932 validation: 0.969800
Iter-400 loss: 1.0357 validation: 0.972400
Iter-400 loss: 0.9141 validation: 0.975600
Iter-400 loss: 0.9610 validation: 0.978800
Iter-400 loss: 0.9126 validation: 0.970600
Iter-450 loss: 0.9066 validation: 0.970800
Iter-450 loss: 1.0156 validation: 0.973600
Iter-450 loss: 0.9566 validation: 0.971400
Iter-450 loss: 0.9792 validation: 0.971400
Iter-500 loss: 0.9148 validation: 0.977200
Iter-500 loss: 0.9329 validation: 0.972400
Iter-500 loss: 0.9854 validation: 0.968600
Iter-500 loss: 0.9386 validation: 0.974200
Iter-550 loss: 0.9232 validation: 0.976000
Iter-550 loss: 1.0070 validation: 0.976400
Iter-550 loss: 0.9635 validation: 0.980000
Iter-550 loss: 0.9396 validation: 0.979200
Iter-600 loss: 0.9448 validation: 0.975800
Iter-600 loss: 0.9474 validation: 0.967600
Iter-600 loss: 0.9388 validation: 0.980000
Iter-600 loss: 0.9842 validation: 0.967200
Iter-650 loss: 0.9358 validation: 0.974000
Iter-650 loss: 0.9596 validation: 0.978400
Iter-650 loss: 1.0114 validation: 0.980000
Iter-650 loss: 0.9331 validation: 0.979200
Iter-700 loss: 0.9399 validation: 0.978400
Iter-700 loss: 0.9381 validation: 0.976200
Iter-700 loss: 0.9387 validation: 0.983800
Iter-700 loss: 0.9778 validation: 0.971200
Iter-750 loss: 0.9445 validation: 0.967200
Iter-750 loss: 0.9511 validation: 0.981000
Iter-750 loss: 0.9407 validation: 0.982400
Iter-750 loss: 0.9479 validation: 0.977600
Iter-800 loss: 0.9755 validation: 0.979400
Iter-800 loss: 0.9503 validation: 0.978400
Iter-800 loss: 0.9593 validation: 0.981600
Iter-800 loss: 0.9595 validation: 0.978200
Iter-850 loss: 0.9529 validation: 0.978600
Iter-850 loss: 0.9826 validation: 0.977800
Iter-850 loss: 0.9588 validation: 0.982200
Iter-850 loss: 0.9695 validation: 0.978200
Iter-900 loss: 0.9553 validation: 0.974600
Iter-900 loss: 0.9593 validation: 0.978000
Iter-900 loss: 0.9614 validation: 0.983000
Iter-900 loss: 0.9743 validation: 0.979000
Iter-950 loss: 0.9627 validation: 0.980200
Iter-950 loss: 0.9671 validation: 0.980800
Iter-950 loss: 0.9596 validation: 0.981200
Iter-950 loss: 0.9746 validation: 0.978800
Iter-1000 loss: 0.9757 validation: 0.977600
Iter-1000 loss: 0.9687 validation: 0.978800
Iter-1000 loss: 0.9942 validation: 0.978800
Iter-1000 loss: 0.9724 validation: 0.979000
Iter-1050 loss: 0.9828 validation: 0.978400
Iter-1050 loss: 0.9876 validation: 0.979800
Iter-1050 loss: 0.9674 validation: 0.982400
Iter-1050 loss: 0.9754 validation: 0.980000
Iter-1100 loss: 0.9731 validation: 0.980800
Iter-1100 loss: 0.9759 validation: 0.981600
Iter-1100 loss: 0.9735 validation: 0.981400
Iter-1100 loss: 0.9789 validation: 0.982600
Iter-1150 loss: 0.9752 validation: 0.981000
Iter-1150 loss: 0.9846 validation: 0.980400
Iter-1150 loss: 0.9732 validation: 0.982800
Iter-1150 loss: 0.9855 validation: 0.981800
Iter-1200 loss: 0.9767 validation: 0.980400
Iter-1200 loss: 0.9806 validation: 0.979600
Iter-1200 loss: 0.9812 validation: 0.984800
Iter-1200 loss: 0.9825 validation: 0.982200
Iter-1250 loss: 0.9911 validation: 0.979200
Iter-1250 loss: 0.9899 validation: 0.983400
Iter-1250 loss: 0.9791 validation: 0.986800
Iter-1250 loss: 0.9860 validation: 0.983200
Iter-1300 loss: 0.9827 validation: 0.981800
Iter-1300 loss: 0.9856 validation: 0.983200
Iter-1300 loss: 0.9808 validation: 0.986600
Iter-1300 loss: 0.9879 validation: 0.980400
Iter-1350 loss: 0.9859 validation: 0.980800
Iter-1350 loss: 0.9949 validation: 0.981200
Iter-1350 loss: 0.9827 validation: 0.985200
Iter-1350 loss: 0.9898 validation: 0.983000
Iter-1400 loss: 0.9883 validation: 0.981800
Iter-1400 loss: 0.9942 validation: 0.981800
Iter-1400 loss: 0.9835 validation: 0.983200
Iter-1400 loss: 0.9902 validation: 0.984400
Iter-1450 loss: 0.9872 validation: 0.979800
Iter-1450 loss: 0.9904 validation: 0.981400
Iter-1450 loss: 0.9982 validation: 0.983400
Iter-1450 loss: 1.0074 validation: 0.982600
Iter-1500 loss: 0.9891 validation: 0.980400
Iter-1500 loss: 0.9923 validation: 0.981000
Iter-1500 loss: 0.9891 validation: 0.984200
Iter-1500 loss: 0.9946 validation: 0.983400
Mean accuracy 1: 0.9794, std: 0.0000
Mean accuracy 2: 0.9821, std: 0.0000
Mean accuracy 3: 0.9837, std: 0.0000
Mean accuracy 4: 0.9822, std: 0.0000
Iter-50 loss: 1.1580 validation: 0.924000
Iter-100 loss: 1.1718 validation: 0.884400
Iter-150 loss: 1.3769 validation: 0.965600
Iter-200 loss: 1.0614 validation: 0.969600
Iter-250 loss: 1.1493 validation: 0.971200
Iter-300 loss: 1.0594 validation: 0.979600
Iter-350 loss: 1.0522 validation: 0.976400
Iter-400 loss: 1.0527 validation: 0.981800
Iter-450 loss: 1.1384 validation: 0.975800
Iter-500 loss: 1.0718 validation: 0.977800
Iter-550 loss: 1.0837 validation: 0.980600
Iter-600 loss: 1.1085 validation: 0.980600
Iter-650 loss: 1.1552 validation: 0.981800
Iter-700 loss: 1.1091 validation: 0.981600
Iter-750 loss: 1.1482 validation: 0.985000
Iter-800 loss: 1.1210 validation: 0.980200
Iter-850 loss: 1.1663 validation: 0.980400
Iter-900 loss: 1.1634 validation: 0.984000
Iter-950 loss: 1.1439 validation: 0.984200
Iter-1000 loss: 1.1377 validation: 0.984200
Iter-1050 loss: 1.1541 validation: 0.984000
Iter-1100 loss: 1.1422 validation: 0.984200
Iter-1150 loss: 1.1480 validation: 0.980000
Iter-1200 loss: 1.1528 validation: 0.983800
Iter-1250 loss: 1.1599 validation: 0.984000
Iter-1300 loss: 1.1575 validation: 0.984400
Iter-1350 loss: 1.1641 validation: 0.986000
Iter-1400 loss: 1.1604 validation: 0.985800
Iter-1450 loss: 1.1631 validation: 0.985000
Iter-1500 loss: 1.1657 validation: 0.987000
Mean accuracy :0.9852,std :0.0000

Mean accuracy :0.9852,std :0.0000
2 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 0.9371 validation: 0.914600
Iter-50 loss: 0.9383 validation: 0.928800
Iter-50 loss: 1.0018 validation: 0.922400
Iter-50 loss: 1.1101 validation: 0.936400
Iter-100 loss: 0.9641 validation: 0.943400
Iter-100 loss: 0.9809 validation: 0.953000
Iter-100 loss: 1.2551 validation: 0.947000
Iter-100 loss: 0.8271 validation: 0.955600
Iter-150 loss: 0.8802 validation: 0.952400
Iter-150 loss: 0.9331 validation: 0.945400
Iter-150 loss: 0.8689 validation: 0.941400
Iter-150 loss: 0.8728 validation: 0.957800
Iter-200 loss: 1.1936 validation: 0.965800
Iter-200 loss: 0.9345 validation: 0.968800
Iter-200 loss: 0.8949 validation: 0.958000
Iter-200 loss: 0.8542 validation: 0.954600
Iter-250 loss: 0.9168 validation: 0.969200
Iter-250 loss: 0.8689 validation: 0.971200
Iter-250 loss: 1.0367 validation: 0.963800
Iter-250 loss: 0.9537 validation: 0.967400
Iter-300 loss: 0.9077 validation: 0.963800
Iter-300 loss: 0.9123 validation: 0.966600
Iter-300 loss: 0.8969 validation: 0.970800
Iter-300 loss: 0.9111 validation: 0.964800
Iter-350 loss: 1.0226 validation: 0.974200
Iter-350 loss: 0.9164 validation: 0.971000
Iter-350 loss: 0.8928 validation: 0.972400
Iter-350 loss: 0.8929 validation: 0.973200
Iter-400 loss: 0.9388 validation: 0.968200
Iter-400 loss: 0.9102 validation: 0.974000
Iter-400 loss: 0.9391 validation: 0.974400
Iter-400 loss: 1.0044 validation: 0.975400
Iter-450 loss: 0.9236 validation: 0.976800
Iter-450 loss: 0.9474 validation: 0.978400
Iter-450 loss: 0.9059 validation: 0.976600
Iter-450 loss: 0.9450 validation: 0.974600
Iter-500 loss: 0.9697 validation: 0.972000
Iter-500 loss: 0.9385 validation: 0.967800
Iter-500 loss: 0.9469 validation: 0.968600
Iter-500 loss: 0.9496 validation: 0.975200
Iter-550 loss: 0.9526 validation: 0.974600
Iter-550 loss: 0.9815 validation: 0.979400
Iter-550 loss: 0.9337 validation: 0.974600
Iter-550 loss: 0.9452 validation: 0.977000
Iter-600 loss: 0.9346 validation: 0.965800
Iter-600 loss: 0.9403 validation: 0.982200
Iter-600 loss: 0.9552 validation: 0.973600
Iter-600 loss: 0.9307 validation: 0.972600
Iter-650 loss: 0.9777 validation: 0.970600
Iter-650 loss: 0.9334 validation: 0.977400
Iter-650 loss: 0.9360 validation: 0.977800
Iter-650 loss: 0.9393 validation: 0.978200
Iter-700 loss: 0.9381 validation: 0.979800
Iter-700 loss: 0.9382 validation: 0.977200
Iter-700 loss: 0.9797 validation: 0.977800
Iter-700 loss: 0.9456 validation: 0.979200
Iter-750 loss: 0.9504 validation: 0.979400
Iter-750 loss: 0.9444 validation: 0.979400
Iter-750 loss: 0.9491 validation: 0.976200
Iter-750 loss: 0.9457 validation: 0.978400
Iter-800 loss: 0.9535 validation: 0.980400
Iter-800 loss: 0.9501 validation: 0.978200
Iter-800 loss: 0.9520 validation: 0.975800
Iter-800 loss: 0.9506 validation: 0.981400
Iter-850 loss: 0.9570 validation: 0.978600
Iter-850 loss: 0.9786 validation: 0.978400
Iter-850 loss: 0.9763 validation: 0.975400
Iter-850 loss: 0.9802 validation: 0.975800
Iter-900 loss: 0.9650 validation: 0.977800
Iter-900 loss: 0.9569 validation: 0.980000
Iter-900 loss: 0.9690 validation: 0.978800
Iter-900 loss: 0.9571 validation: 0.982200
Iter-950 loss: 0.9673 validation: 0.977400
Iter-950 loss: 0.9786 validation: 0.978200
Iter-950 loss: 0.9635 validation: 0.978000
Iter-950 loss: 0.9957 validation: 0.977200
Iter-1000 loss: 0.9700 validation: 0.980600
Iter-1000 loss: 0.9787 validation: 0.980200
Iter-1000 loss: 0.9678 validation: 0.977800
Iter-1000 loss: 0.9903 validation: 0.980000
Iter-1050 loss: 0.9753 validation: 0.980600
Iter-1050 loss: 0.9742 validation: 0.981200
Iter-1050 loss: 0.9735 validation: 0.977600
Iter-1050 loss: 0.9746 validation: 0.980800
Iter-1100 loss: 0.9776 validation: 0.978600
Iter-1100 loss: 0.9775 validation: 0.980600
Iter-1100 loss: 0.9771 validation: 0.978000
Iter-1100 loss: 0.9761 validation: 0.982000
Iter-1150 loss: 0.9809 validation: 0.980800
Iter-1150 loss: 0.9837 validation: 0.981000
Iter-1150 loss: 0.9815 validation: 0.983000
Iter-1150 loss: 0.9783 validation: 0.981800
Iter-1200 loss: 0.9849 validation: 0.980200
Iter-1200 loss: 1.0005 validation: 0.978800
Iter-1200 loss: 0.9845 validation: 0.982400
Iter-1200 loss: 0.9821 validation: 0.979800
Iter-1250 loss: 0.9863 validation: 0.982200
Iter-1250 loss: 1.0192 validation: 0.983000
Iter-1250 loss: 0.9843 validation: 0.981600
Iter-1250 loss: 0.9847 validation: 0.983800
Iter-1300 loss: 0.9935 validation: 0.981000
Iter-1300 loss: 0.9875 validation: 0.982400
Iter-1300 loss: 0.9860 validation: 0.981000
Iter-1300 loss: 0.9872 validation: 0.983000
Iter-1350 loss: 0.9917 validation: 0.982000
Iter-1350 loss: 0.9912 validation: 0.982600
Iter-1350 loss: 0.9876 validation: 0.982600
Iter-1350 loss: 0.9911 validation: 0.980200
Iter-1400 loss: 0.9929 validation: 0.982000
Iter-1400 loss: 0.9906 validation: 0.982600
Iter-1400 loss: 0.9894 validation: 0.982600
Iter-1400 loss: 0.9895 validation: 0.983600
Iter-1450 loss: 0.9936 validation: 0.981600
Iter-1450 loss: 0.9925 validation: 0.982800
Iter-1450 loss: 0.9920 validation: 0.985000
Iter-1450 loss: 0.9914 validation: 0.982800
Iter-1500 loss: 0.9949 validation: 0.979600
Iter-1500 loss: 0.9936 validation: 0.981000
Iter-1500 loss: 0.9939 validation: 0.983800
Iter-1500 loss: 0.9925 validation: 0.982400
Mean accuracy 1: 0.9764, std: 0.0000
Mean accuracy 2: 0.9828, std: 0.0000
Mean accuracy 3: 0.9805, std: 0.0000
Mean accuracy 4: 0.9805, std: 0.0000
Iter-50 loss: 1.1961 validation: 0.836200
Iter-100 loss: 1.4627 validation: 0.921600
Iter-150 loss: 1.1452 validation: 0.965600
Iter-200 loss: 1.0588 validation: 0.969200
Iter-250 loss: 1.0231 validation: 0.971600
Iter-300 loss: 1.0314 validation: 0.977600
Iter-350 loss: 1.0418 validation: 0.974200
Iter-400 loss: 1.1349 validation: 0.971800
Iter-450 loss: 1.0622 validation: 0.977200
Iter-500 loss: 1.1441 validation: 0.980200
Iter-550 loss: 1.0696 validation: 0.976400
Iter-600 loss: 1.1079 validation: 0.980000
Iter-650 loss: 1.1412 validation: 0.976400
Iter-700 loss: 1.0976 validation: 0.981000
Iter-750 loss: 1.1099 validation: 0.983800
Iter-800 loss: 1.1115 validation: 0.982400
Iter-850 loss: 1.1516 validation: 0.982200
Iter-900 loss: 1.1197 validation: 0.981800
Iter-950 loss: 1.1210 validation: 0.981400
Iter-1000 loss: 1.1352 validation: 0.984600
Iter-1050 loss: 1.1246 validation: 0.985600
Iter-1100 loss: 1.1674 validation: 0.984400
Iter-1150 loss: 1.1329 validation: 0.983200
Iter-1200 loss: 1.1381 validation: 0.985600
Iter-1250 loss: 1.1506 validation: 0.980200
Iter-1300 loss: 1.1442 validation: 0.984000
Iter-1350 loss: 1.1539 validation: 0.984800
Iter-1400 loss: 1.1485 validation: 0.984400
Iter-1450 loss: 1.1525 validation: 0.983400
Iter-1500 loss: 1.1579 validation: 0.985000
Mean accuracy :0.9835,std :0.0000

Mean accuracy :0.9835,std :0.0000
3 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.2631 validation: 0.901200
Iter-50 loss: 0.9480 validation: 0.903800
Iter-50 loss: 1.0447 validation: 0.920800
Iter-50 loss: 0.8832 validation: 0.936000
Iter-100 loss: 0.9425 validation: 0.955800
Iter-100 loss: 0.9532 validation: 0.936800
Iter-100 loss: 0.9639 validation: 0.950400
Iter-100 loss: 1.0570 validation: 0.942400
Iter-150 loss: 0.8772 validation: 0.958200
Iter-150 loss: 0.8581 validation: 0.961000
Iter-150 loss: 1.0445 validation: 0.952000
Iter-150 loss: 0.8364 validation: 0.957200
Iter-200 loss: 0.8913 validation: 0.967600
Iter-200 loss: 0.9565 validation: 0.957200
Iter-200 loss: 0.8913 validation: 0.957600
Iter-200 loss: 0.9141 validation: 0.946400
Iter-250 loss: 0.9888 validation: 0.966400
Iter-250 loss: 0.9211 validation: 0.964400
Iter-250 loss: 0.9338 validation: 0.971000
Iter-250 loss: 0.9604 validation: 0.960200
Iter-300 loss: 0.8991 validation: 0.971800
Iter-300 loss: 0.8985 validation: 0.971800
Iter-300 loss: 0.9158 validation: 0.970600
Iter-300 loss: 0.8940 validation: 0.971000
Iter-350 loss: 0.9016 validation: 0.972600
Iter-350 loss: 0.8750 validation: 0.972000
Iter-350 loss: 0.8909 validation: 0.966200
Iter-350 loss: 0.8991 validation: 0.976000
Iter-400 loss: 0.9233 validation: 0.978400
Iter-400 loss: 1.0188 validation: 0.971600
Iter-400 loss: 1.0647 validation: 0.975800
Iter-400 loss: 0.9089 validation: 0.974800
Iter-450 loss: 0.9385 validation: 0.975000
Iter-450 loss: 0.9443 validation: 0.976600
Iter-450 loss: 0.9768 validation: 0.972000
Iter-450 loss: 0.9803 validation: 0.979400
Iter-500 loss: 0.9293 validation: 0.979400
Iter-500 loss: 0.8972 validation: 0.976600
Iter-500 loss: 0.9389 validation: 0.973400
Iter-500 loss: 0.9877 validation: 0.979200
Iter-550 loss: 0.9272 validation: 0.978800
Iter-550 loss: 0.9617 validation: 0.966200
Iter-550 loss: 0.9259 validation: 0.978800
Iter-550 loss: 0.9760 validation: 0.974200
Iter-600 loss: 0.9353 validation: 0.981600
Iter-600 loss: 0.9509 validation: 0.981600
Iter-600 loss: 0.9670 validation: 0.975000
Iter-600 loss: 0.9286 validation: 0.979400
Iter-650 loss: 0.9455 validation: 0.982200
Iter-650 loss: 0.9233 validation: 0.978000
Iter-650 loss: 0.9566 validation: 0.975400
Iter-650 loss: 0.9412 validation: 0.982000
Iter-700 loss: 0.9594 validation: 0.981600
Iter-700 loss: 0.9341 validation: 0.981600
Iter-700 loss: 0.9507 validation: 0.978400
Iter-700 loss: 1.0205 validation: 0.983000
Iter-750 loss: 0.9518 validation: 0.982800
Iter-750 loss: 0.9363 validation: 0.981000
Iter-750 loss: 0.9532 validation: 0.980000
Iter-750 loss: 1.0045 validation: 0.980200
Iter-800 loss: 0.9571 validation: 0.978000
Iter-800 loss: 0.9456 validation: 0.973000
Iter-800 loss: 0.9584 validation: 0.978600
Iter-800 loss: 1.0170 validation: 0.978200
Iter-850 loss: 0.9862 validation: 0.980400
Iter-850 loss: 1.0866 validation: 0.981000
Iter-850 loss: 1.0762 validation: 0.981600
Iter-850 loss: 0.9600 validation: 0.973400
Iter-900 loss: 0.9827 validation: 0.981600
Iter-900 loss: 0.9577 validation: 0.981800
Iter-900 loss: 0.9741 validation: 0.981000
Iter-900 loss: 0.9628 validation: 0.983400
Iter-950 loss: 0.9715 validation: 0.981800
Iter-950 loss: 0.9577 validation: 0.982400
Iter-950 loss: 1.0118 validation: 0.980000
Iter-950 loss: 0.9757 validation: 0.978800
Iter-1000 loss: 0.9765 validation: 0.982400
Iter-1000 loss: 0.9701 validation: 0.982800
Iter-1000 loss: 1.0009 validation: 0.983000
Iter-1000 loss: 0.9718 validation: 0.983400
Iter-1050 loss: 0.9885 validation: 0.983600
Iter-1050 loss: 0.9653 validation: 0.985000
Iter-1050 loss: 0.9831 validation: 0.981800
Iter-1050 loss: 0.9786 validation: 0.986600
Iter-1100 loss: 0.9843 validation: 0.978400
Iter-1100 loss: 0.9793 validation: 0.981200
Iter-1100 loss: 0.9865 validation: 0.980200
Iter-1100 loss: 0.9780 validation: 0.984000
Iter-1150 loss: 0.9857 validation: 0.984400
Iter-1150 loss: 0.9709 validation: 0.982800
Iter-1150 loss: 1.0041 validation: 0.982600
Iter-1150 loss: 0.9830 validation: 0.985800
Iter-1200 loss: 0.9880 validation: 0.980000
Iter-1200 loss: 0.9814 validation: 0.981800
Iter-1200 loss: 1.0099 validation: 0.981200
Iter-1200 loss: 0.9894 validation: 0.983600
Iter-1250 loss: 0.9903 validation: 0.982600
Iter-1250 loss: 0.9829 validation: 0.983600
Iter-1250 loss: 0.9962 validation: 0.979800
Iter-1250 loss: 0.9891 validation: 0.983600
Iter-1300 loss: 0.9920 validation: 0.982000
Iter-1300 loss: 0.9819 validation: 0.982000
Iter-1300 loss: 0.9960 validation: 0.981600
Iter-1300 loss: 0.9899 validation: 0.983600
Iter-1350 loss: 0.9948 validation: 0.984200
Iter-1350 loss: 0.9825 validation: 0.982400
Iter-1350 loss: 0.9983 validation: 0.982400
Iter-1350 loss: 0.9913 validation: 0.983000
Iter-1400 loss: 1.0038 validation: 0.980800
Iter-1400 loss: 0.9833 validation: 0.981000
Iter-1400 loss: 0.9998 validation: 0.981600
Iter-1400 loss: 1.0021 validation: 0.984800
Iter-1450 loss: 1.0005 validation: 0.982600
Iter-1450 loss: 0.9859 validation: 0.983800
Iter-1450 loss: 1.0035 validation: 0.982800
Iter-1450 loss: 0.9947 validation: 0.985200
Iter-1500 loss: 1.0011 validation: 0.984600
Iter-1500 loss: 0.9870 validation: 0.983400
Iter-1500 loss: 1.0025 validation: 0.984000
Iter-1500 loss: 0.9964 validation: 0.985600
Mean accuracy 1: 0.9819, std: 0.0000
Mean accuracy 2: 0.9817, std: 0.0000
Mean accuracy 3: 0.9818, std: 0.0000
Mean accuracy 4: 0.9817, std: 0.0000
Iter-50 loss: 1.0817 validation: 0.836800
Iter-100 loss: 1.2205 validation: 0.924800
Iter-150 loss: 1.0449 validation: 0.964800
Iter-200 loss: 1.2206 validation: 0.975400
Iter-250 loss: 1.0364 validation: 0.976400
Iter-300 loss: 1.1222 validation: 0.972000
Iter-350 loss: 1.0641 validation: 0.976000
Iter-400 loss: 1.1604 validation: 0.971000
Iter-450 loss: 1.3230 validation: 0.975400
Iter-500 loss: 1.1429 validation: 0.980200
Iter-550 loss: 1.1846 validation: 0.977600
Iter-600 loss: 1.0939 validation: 0.979400
Iter-650 loss: 1.0988 validation: 0.981000
Iter-700 loss: 1.1068 validation: 0.980400
Iter-750 loss: 1.1165 validation: 0.978200
Iter-800 loss: 1.1654 validation: 0.983800
Iter-850 loss: 1.1275 validation: 0.981800
Iter-900 loss: 1.1273 validation: 0.981400
Iter-950 loss: 1.1312 validation: 0.978800
Iter-1000 loss: 1.1360 validation: 0.981800
Iter-1050 loss: 1.1374 validation: 0.982000
Iter-1100 loss: 1.1722 validation: 0.982400
Iter-1150 loss: 1.1450 validation: 0.983000
Iter-1200 loss: 1.1589 validation: 0.985400
Iter-1250 loss: 1.1524 validation: 0.985200
Iter-1300 loss: 1.1584 validation: 0.982400
Iter-1350 loss: 1.1599 validation: 0.982800
Iter-1400 loss: 1.1643 validation: 0.982600
Iter-1450 loss: 1.1598 validation: 0.984600
Iter-1500 loss: 1.1633 validation: 0.984800
Mean accuracy :0.9841,std :0.0000

Mean accuracy :0.9841,std :0.0000
4 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.1522 validation: 0.943400
Iter-50 loss: 1.0530 validation: 0.914400
Iter-50 loss: 1.1077 validation: 0.927600
Iter-50 loss: 1.0342 validation: 0.920400
Iter-100 loss: 0.8492 validation: 0.947200
Iter-100 loss: 0.8083 validation: 0.952000
Iter-100 loss: 0.9289 validation: 0.949000
Iter-100 loss: 0.9839 validation: 0.941400
Iter-150 loss: 0.9767 validation: 0.963600
Iter-150 loss: 0.9301 validation: 0.943800
Iter-150 loss: 0.8547 validation: 0.950600
Iter-150 loss: 0.8687 validation: 0.936600
Iter-200 loss: 0.8803 validation: 0.963400
Iter-200 loss: 1.0384 validation: 0.963800
Iter-200 loss: 0.9558 validation: 0.953800
Iter-200 loss: 0.8913 validation: 0.964200
Iter-250 loss: 0.8963 validation: 0.971800
Iter-250 loss: 0.9901 validation: 0.970800
Iter-250 loss: 1.2201 validation: 0.961800
Iter-250 loss: 0.9318 validation: 0.973400
Iter-300 loss: 0.9479 validation: 0.973800
Iter-300 loss: 0.8927 validation: 0.969800
Iter-300 loss: 0.9505 validation: 0.965400
Iter-300 loss: 0.8795 validation: 0.975400
Iter-350 loss: 0.9021 validation: 0.973800
Iter-350 loss: 0.8781 validation: 0.976200
Iter-350 loss: 0.9703 validation: 0.971800
Iter-350 loss: 0.9192 validation: 0.970200
Iter-400 loss: 0.9238 validation: 0.964400
Iter-400 loss: 0.9226 validation: 0.970800
Iter-400 loss: 0.9076 validation: 0.975000
Iter-400 loss: 0.9163 validation: 0.978800
Iter-450 loss: 0.9662 validation: 0.976000
Iter-450 loss: 0.9622 validation: 0.971600
Iter-450 loss: 0.9285 validation: 0.973400
Iter-450 loss: 0.9000 validation: 0.977800
Iter-500 loss: 0.9170 validation: 0.970400
Iter-500 loss: 0.9114 validation: 0.975800
Iter-500 loss: 0.9282 validation: 0.973800
Iter-500 loss: 0.9171 validation: 0.965000
Iter-550 loss: 0.9444 validation: 0.975200
Iter-550 loss: 0.9127 validation: 0.974800
Iter-550 loss: 0.9752 validation: 0.972800
Iter-550 loss: 0.9263 validation: 0.979600
Iter-600 loss: 0.9369 validation: 0.978400
Iter-600 loss: 0.9167 validation: 0.971800
Iter-600 loss: 0.9361 validation: 0.973200
Iter-600 loss: 0.9435 validation: 0.974000
Iter-650 loss: 0.9561 validation: 0.974000
Iter-650 loss: 0.9253 validation: 0.976000
Iter-650 loss: 0.9677 validation: 0.979000
Iter-650 loss: 0.9343 validation: 0.977400
Iter-700 loss: 0.9486 validation: 0.978400
Iter-700 loss: 0.9325 validation: 0.981200
Iter-700 loss: 0.9763 validation: 0.974800
Iter-700 loss: 0.9675 validation: 0.973000
Iter-750 loss: 0.9552 validation: 0.977200
Iter-750 loss: 0.9464 validation: 0.978200
Iter-750 loss: 0.9712 validation: 0.977200
Iter-750 loss: 0.9495 validation: 0.977600
Iter-800 loss: 0.9777 validation: 0.976800
Iter-800 loss: 0.9461 validation: 0.980800
Iter-800 loss: 0.9798 validation: 0.979400
Iter-800 loss: 0.9679 validation: 0.978000
Iter-850 loss: 1.0103 validation: 0.978600
Iter-850 loss: 0.9484 validation: 0.978400
Iter-850 loss: 1.0164 validation: 0.976800
Iter-850 loss: 0.9992 validation: 0.977800
Iter-900 loss: 0.9923 validation: 0.979400
Iter-900 loss: 0.9970 validation: 0.976200
Iter-900 loss: 0.9768 validation: 0.975000
Iter-900 loss: 0.9670 validation: 0.982200
Iter-950 loss: 0.9769 validation: 0.981800
Iter-950 loss: 0.9621 validation: 0.980800
Iter-950 loss: 1.0575 validation: 0.980200
Iter-950 loss: 0.9812 validation: 0.981800
Iter-1000 loss: 0.9821 validation: 0.980200
Iter-1000 loss: 0.9881 validation: 0.981200
Iter-1000 loss: 1.0344 validation: 0.980800
Iter-1000 loss: 0.9814 validation: 0.982200
Iter-1050 loss: 0.9833 validation: 0.980800
Iter-1050 loss: 0.9696 validation: 0.979800
Iter-1050 loss: 0.9886 validation: 0.976800
Iter-1050 loss: 0.9756 validation: 0.980000
Iter-1100 loss: 0.9874 validation: 0.982600
Iter-1100 loss: 0.9788 validation: 0.980400
Iter-1100 loss: 1.0147 validation: 0.979800
Iter-1100 loss: 0.9790 validation: 0.981400
Iter-1150 loss: 0.9906 validation: 0.979800
Iter-1150 loss: 1.0041 validation: 0.981200
Iter-1150 loss: 0.9989 validation: 0.982200
Iter-1150 loss: 0.9935 validation: 0.982200
Iter-1200 loss: 0.9940 validation: 0.981400
Iter-1200 loss: 0.9784 validation: 0.983200
Iter-1200 loss: 0.9988 validation: 0.981600
Iter-1200 loss: 0.9843 validation: 0.982800
Iter-1250 loss: 0.9951 validation: 0.982400
Iter-1250 loss: 0.9803 validation: 0.983200
Iter-1250 loss: 1.0061 validation: 0.983200
Iter-1250 loss: 1.0055 validation: 0.980800
Iter-1300 loss: 0.9973 validation: 0.982000
Iter-1300 loss: 1.0181 validation: 0.984000
Iter-1300 loss: 1.0080 validation: 0.982800
Iter-1300 loss: 0.9890 validation: 0.982400
Iter-1350 loss: 0.9991 validation: 0.984000
Iter-1350 loss: 0.9849 validation: 0.984000
Iter-1350 loss: 1.0032 validation: 0.984200
Iter-1350 loss: 0.9927 validation: 0.981400
Iter-1400 loss: 1.0013 validation: 0.982200
Iter-1400 loss: 0.9862 validation: 0.986000
Iter-1400 loss: 1.0263 validation: 0.982400
Iter-1400 loss: 0.9932 validation: 0.981600
Iter-1450 loss: 1.0022 validation: 0.983400
Iter-1450 loss: 0.9871 validation: 0.985000
Iter-1450 loss: 1.0196 validation: 0.982200
Iter-1450 loss: 0.9953 validation: 0.984000
Iter-1500 loss: 1.0042 validation: 0.981400
Iter-1500 loss: 0.9904 validation: 0.984400
Iter-1500 loss: 1.0088 validation: 0.982800
Iter-1500 loss: 0.9948 validation: 0.984600
Mean accuracy 1: 0.9803, std: 0.0000
Mean accuracy 2: 0.9815, std: 0.0000
Mean accuracy 3: 0.9793, std: 0.0000
Mean accuracy 4: 0.9820, std: 0.0000
Iter-50 loss: 1.0149 validation: 0.907800
Iter-100 loss: 1.2392 validation: 0.937800
Iter-150 loss: 0.9990 validation: 0.961800
Iter-200 loss: 1.0590 validation: 0.942400
Iter-250 loss: 1.0526 validation: 0.972000
Iter-300 loss: 1.0535 validation: 0.968000
Iter-350 loss: 1.0433 validation: 0.976200
Iter-400 loss: 1.0412 validation: 0.981000
Iter-450 loss: 1.0867 validation: 0.973200
Iter-500 loss: 1.0636 validation: 0.980800
Iter-550 loss: 1.0740 validation: 0.981400
Iter-600 loss: 1.0826 validation: 0.979000
Iter-650 loss: 1.0923 validation: 0.979800
Iter-700 loss: 1.1125 validation: 0.979800
Iter-750 loss: 1.1019 validation: 0.981200
Iter-800 loss: 1.1014 validation: 0.981600
Iter-850 loss: 1.1036 validation: 0.983400
Iter-900 loss: 1.1073 validation: 0.982400
Iter-950 loss: 1.1097 validation: 0.983400
Iter-1000 loss: 1.1135 validation: 0.977800
Iter-1050 loss: 1.1229 validation: 0.981600
Iter-1100 loss: 1.1258 validation: 0.981000
Iter-1150 loss: 1.1435 validation: 0.983600
Iter-1200 loss: 1.1341 validation: 0.982800
Iter-1250 loss: 1.1357 validation: 0.984000
Iter-1300 loss: 1.1380 validation: 0.982600
Iter-1350 loss: 1.1434 validation: 0.984800
Iter-1400 loss: 1.1470 validation: 0.981600
Iter-1450 loss: 1.1559 validation: 0.984600
Iter-1500 loss: 1.1529 validation: 0.984200
Mean accuracy :0.9837,std :0.0000

Mean accuracy :0.9837,std :0.0000
5 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.1846 validation: 0.848600
Iter-50 loss: 0.8763 validation: 0.920600
Iter-50 loss: 1.2480 validation: 0.917400
Iter-50 loss: 1.1132 validation: 0.879800
Iter-100 loss: 0.9724 validation: 0.932400
Iter-100 loss: 0.8965 validation: 0.949600
Iter-100 loss: 1.0404 validation: 0.953400
Iter-100 loss: 0.9847 validation: 0.937000
Iter-150 loss: 0.8589 validation: 0.963800
Iter-150 loss: 0.8486 validation: 0.959000
Iter-150 loss: 0.9204 validation: 0.964000
Iter-150 loss: 0.9826 validation: 0.961000
Iter-200 loss: 0.8835 validation: 0.960600
Iter-200 loss: 0.8533 validation: 0.963600
Iter-200 loss: 0.9640 validation: 0.927800
Iter-200 loss: 0.8717 validation: 0.949600
Iter-250 loss: 1.0168 validation: 0.947600
Iter-250 loss: 0.8704 validation: 0.963200
Iter-250 loss: 0.9162 validation: 0.960800
Iter-250 loss: 0.8750 validation: 0.959000
Iter-300 loss: 0.9920 validation: 0.965800
Iter-300 loss: 0.8835 validation: 0.967200
Iter-300 loss: 0.9186 validation: 0.973000
Iter-300 loss: 0.9880 validation: 0.964000
Iter-350 loss: 0.9703 validation: 0.973000
Iter-350 loss: 0.9396 validation: 0.968800
Iter-350 loss: 0.9338 validation: 0.964200
Iter-350 loss: 0.8989 validation: 0.972800
Iter-400 loss: 0.9389 validation: 0.973000
Iter-400 loss: 0.9306 validation: 0.967200
Iter-400 loss: 0.8816 validation: 0.975600
Iter-400 loss: 0.9124 validation: 0.978000
Iter-450 loss: 0.9168 validation: 0.966000
Iter-450 loss: 0.9093 validation: 0.974200
Iter-450 loss: 0.9145 validation: 0.972600
Iter-450 loss: 0.9106 validation: 0.977800
Iter-500 loss: 0.9677 validation: 0.974600
Iter-500 loss: 1.1111 validation: 0.970200
Iter-500 loss: 0.9745 validation: 0.967800
Iter-500 loss: 0.9201 validation: 0.969000
Iter-550 loss: 0.9303 validation: 0.976200
Iter-550 loss: 0.9270 validation: 0.975000
Iter-550 loss: 0.9241 validation: 0.976400
Iter-550 loss: 0.9349 validation: 0.974600
Iter-600 loss: 0.9448 validation: 0.976000
Iter-600 loss: 0.9704 validation: 0.972600
Iter-600 loss: 0.9151 validation: 0.979600
Iter-600 loss: 0.9410 validation: 0.978200
Iter-650 loss: 0.9875 validation: 0.976200
Iter-650 loss: 0.9767 validation: 0.977000
Iter-650 loss: 0.9278 validation: 0.978600
Iter-650 loss: 0.9428 validation: 0.980800
Iter-700 loss: 0.9523 validation: 0.971400
Iter-700 loss: 0.9460 validation: 0.973600
Iter-700 loss: 0.9433 validation: 0.976600
Iter-700 loss: 0.9510 validation: 0.975600
Iter-750 loss: 0.9998 validation: 0.979400
Iter-750 loss: 0.9557 validation: 0.979000
Iter-750 loss: 1.0632 validation: 0.982000
Iter-750 loss: 0.9779 validation: 0.981600
Iter-800 loss: 0.9614 validation: 0.979000
Iter-800 loss: 0.9522 validation: 0.973200
Iter-800 loss: 1.0206 validation: 0.978200
Iter-800 loss: 0.9598 validation: 0.978600
Iter-850 loss: 0.9693 validation: 0.977400
Iter-850 loss: 0.9594 validation: 0.970800
Iter-850 loss: 0.9498 validation: 0.978800
Iter-850 loss: 0.9812 validation: 0.978000
Iter-900 loss: 0.9761 validation: 0.978800
Iter-900 loss: 0.9659 validation: 0.978000
Iter-900 loss: 0.9555 validation: 0.976000
Iter-900 loss: 0.9709 validation: 0.981400
Iter-950 loss: 0.9749 validation: 0.978600
Iter-950 loss: 0.9794 validation: 0.978200
Iter-950 loss: 0.9781 validation: 0.979200
Iter-950 loss: 0.9739 validation: 0.980600
Iter-1000 loss: 1.0142 validation: 0.977600
Iter-1000 loss: 0.9709 validation: 0.978400
Iter-1000 loss: 0.9570 validation: 0.980400
Iter-1000 loss: 0.9764 validation: 0.982600
Iter-1050 loss: 0.9840 validation: 0.977600
Iter-1050 loss: 1.0036 validation: 0.979400
Iter-1050 loss: 1.0077 validation: 0.983800
Iter-1050 loss: 0.9871 validation: 0.981600
Iter-1100 loss: 0.9876 validation: 0.979800
Iter-1100 loss: 0.9994 validation: 0.979400
Iter-1100 loss: 0.9634 validation: 0.983400
Iter-1100 loss: 0.9837 validation: 0.982400
Iter-1150 loss: 0.9937 validation: 0.982000
Iter-1150 loss: 0.9794 validation: 0.978600
Iter-1150 loss: 0.9647 validation: 0.982600
Iter-1150 loss: 0.9840 validation: 0.981200
Iter-1200 loss: 0.9906 validation: 0.981600
Iter-1200 loss: 0.9826 validation: 0.979800
Iter-1200 loss: 0.9685 validation: 0.982800
Iter-1200 loss: 0.9875 validation: 0.981200
Iter-1250 loss: 0.9936 validation: 0.978600
Iter-1250 loss: 0.9852 validation: 0.982400
Iter-1250 loss: 1.0238 validation: 0.981800
Iter-1250 loss: 0.9905 validation: 0.981800
Iter-1300 loss: 1.0034 validation: 0.981000
Iter-1300 loss: 0.9877 validation: 0.980200
Iter-1300 loss: 0.9738 validation: 0.985000
Iter-1300 loss: 0.9924 validation: 0.982400
Iter-1350 loss: 0.9992 validation: 0.969000
Iter-1350 loss: 0.9887 validation: 0.979800
Iter-1350 loss: 0.9836 validation: 0.975400
Iter-1350 loss: 0.9996 validation: 0.975200
Iter-1400 loss: 1.0063 validation: 0.981600
Iter-1400 loss: 1.0005 validation: 0.982800
Iter-1400 loss: 0.9775 validation: 0.983200
Iter-1400 loss: 0.9974 validation: 0.984200
Iter-1450 loss: 1.0021 validation: 0.982400
Iter-1450 loss: 0.9972 validation: 0.981600
Iter-1450 loss: 0.9824 validation: 0.981800
Iter-1450 loss: 0.9978 validation: 0.982800
Iter-1500 loss: 1.0038 validation: 0.980600
Iter-1500 loss: 0.9948 validation: 0.979200
Iter-1500 loss: 0.9820 validation: 0.978600
Iter-1500 loss: 0.9996 validation: 0.981200
Mean accuracy 1: 0.9798, std: 0.0000
Mean accuracy 2: 0.9777, std: 0.0000
Mean accuracy 3: 0.9797, std: 0.0000
Mean accuracy 4: 0.9811, std: 0.0000
Iter-50 loss: 1.1422 validation: 0.918800
Iter-100 loss: 1.1466 validation: 0.955400
Iter-150 loss: 1.0356 validation: 0.964000
Iter-200 loss: 1.0871 validation: 0.972600
Iter-250 loss: 1.0110 validation: 0.969800
Iter-300 loss: 1.2239 validation: 0.976600
Iter-350 loss: 1.0467 validation: 0.971000
Iter-400 loss: 1.1788 validation: 0.974600
Iter-450 loss: 1.0798 validation: 0.978000
Iter-500 loss: 1.0742 validation: 0.973800
Iter-550 loss: 1.0983 validation: 0.980600
Iter-600 loss: 1.0951 validation: 0.981200
Iter-650 loss: 1.0932 validation: 0.976400
Iter-700 loss: 1.0892 validation: 0.980400
Iter-750 loss: 1.1743 validation: 0.975800
Iter-800 loss: 1.1039 validation: 0.982600
Iter-850 loss: 1.1132 validation: 0.981000
Iter-900 loss: 1.1217 validation: 0.981400
Iter-950 loss: 1.1225 validation: 0.983800
Iter-1000 loss: 1.1647 validation: 0.984600
Iter-1050 loss: 1.1357 validation: 0.983400
Iter-1100 loss: 1.1465 validation: 0.985000
Iter-1150 loss: 1.1518 validation: 0.982200
Iter-1200 loss: 1.1472 validation: 0.983800
Iter-1250 loss: 1.1471 validation: 0.982600
Iter-1300 loss: 1.1713 validation: 0.978200
Iter-1350 loss: 1.1529 validation: 0.985000
Iter-1400 loss: 1.1559 validation: 0.983200
Iter-1450 loss: 1.1571 validation: 0.983800
Iter-1500 loss: 1.2190 validation: 0.984000
Mean accuracy :0.9842,std :0.0000

Mean accuracy :0.9842,std :0.0000
6 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 0.8716 validation: 0.905000
Iter-50 loss: 0.9539 validation: 0.925200
Iter-50 loss: 0.8715 validation: 0.920800
Iter-50 loss: 1.1390 validation: 0.917600
Iter-100 loss: 0.9079 validation: 0.953000
Iter-100 loss: 0.8443 validation: 0.952000
Iter-100 loss: 0.9591 validation: 0.930400
Iter-100 loss: 0.9431 validation: 0.942800
Iter-150 loss: 0.8634 validation: 0.951200
Iter-150 loss: 0.8453 validation: 0.956000
Iter-150 loss: 0.9512 validation: 0.957600
Iter-150 loss: 0.8992 validation: 0.962000
Iter-200 loss: 0.9344 validation: 0.964400
Iter-200 loss: 0.8778 validation: 0.966200
Iter-200 loss: 0.8618 validation: 0.964000
Iter-200 loss: 0.8890 validation: 0.964800
Iter-250 loss: 0.9047 validation: 0.968800
Iter-250 loss: 0.8667 validation: 0.956000
Iter-250 loss: 1.0105 validation: 0.949200
Iter-250 loss: 0.9153 validation: 0.971000
Iter-300 loss: 0.9228 validation: 0.968400
Iter-300 loss: 1.0007 validation: 0.965200
Iter-300 loss: 0.8798 validation: 0.966400
Iter-300 loss: 1.0281 validation: 0.966200
Iter-350 loss: 0.9061 validation: 0.966800
Iter-350 loss: 0.8979 validation: 0.968000
Iter-350 loss: 0.9269 validation: 0.968600
Iter-350 loss: 0.9525 validation: 0.972000
Iter-400 loss: 0.9112 validation: 0.975000
Iter-400 loss: 0.9612 validation: 0.968000
Iter-400 loss: 0.9040 validation: 0.967200
Iter-400 loss: 0.8996 validation: 0.974000
Iter-450 loss: 0.9234 validation: 0.977000
Iter-450 loss: 0.8964 validation: 0.976200
Iter-450 loss: 0.9165 validation: 0.975400
Iter-450 loss: 0.9413 validation: 0.975800
Iter-500 loss: 0.9081 validation: 0.976800
Iter-500 loss: 0.9121 validation: 0.975600
Iter-500 loss: 0.9906 validation: 0.968400
Iter-500 loss: 0.9219 validation: 0.965600
Iter-550 loss: 0.9279 validation: 0.975400
Iter-550 loss: 0.9926 validation: 0.976400
Iter-550 loss: 0.9242 validation: 0.974600
Iter-550 loss: 0.9207 validation: 0.968000
Iter-600 loss: 0.9558 validation: 0.977800
Iter-600 loss: 0.9325 validation: 0.977600
Iter-600 loss: 0.9298 validation: 0.971600
Iter-600 loss: 0.9276 validation: 0.974200
Iter-650 loss: 0.9421 validation: 0.977800
Iter-650 loss: 0.9407 validation: 0.976400
Iter-650 loss: 0.9481 validation: 0.975000
Iter-650 loss: 0.9577 validation: 0.975800
Iter-700 loss: 0.9413 validation: 0.977800
Iter-700 loss: 0.9540 validation: 0.975600
Iter-700 loss: 0.9534 validation: 0.979400
Iter-700 loss: 0.9482 validation: 0.979200
Iter-750 loss: 0.9521 validation: 0.980000
Iter-750 loss: 0.9529 validation: 0.980600
Iter-750 loss: 0.9544 validation: 0.975000
Iter-750 loss: 0.9650 validation: 0.976600
Iter-800 loss: 0.9768 validation: 0.979600
Iter-800 loss: 0.9599 validation: 0.975000
Iter-800 loss: 1.1212 validation: 0.975000
Iter-800 loss: 0.9538 validation: 0.978400
Iter-850 loss: 0.9584 validation: 0.981800
Iter-850 loss: 0.9689 validation: 0.978800
Iter-850 loss: 1.0072 validation: 0.978600
Iter-850 loss: 0.9847 validation: 0.978400
Iter-900 loss: 0.9650 validation: 0.980600
Iter-900 loss: 0.9609 validation: 0.982600
Iter-900 loss: 0.9657 validation: 0.972000
Iter-900 loss: 0.9917 validation: 0.978800
Iter-950 loss: 0.9726 validation: 0.976600
Iter-950 loss: 0.9636 validation: 0.980800
Iter-950 loss: 0.9796 validation: 0.977200
Iter-950 loss: 0.9858 validation: 0.979600
Iter-1000 loss: 0.9941 validation: 0.979200
Iter-1000 loss: 0.9686 validation: 0.981000
Iter-1000 loss: 0.9869 validation: 0.978000
Iter-1000 loss: 1.0335 validation: 0.982200
Iter-1050 loss: 0.9801 validation: 0.981800
Iter-1050 loss: 0.9760 validation: 0.981400
Iter-1050 loss: 0.9994 validation: 0.976600
Iter-1050 loss: 0.9850 validation: 0.980600
Iter-1100 loss: 0.9879 validation: 0.981200
Iter-1100 loss: 0.9830 validation: 0.981400
Iter-1100 loss: 0.9817 validation: 0.981600
Iter-1100 loss: 0.9824 validation: 0.980400
Iter-1150 loss: 0.9903 validation: 0.980800
Iter-1150 loss: 0.9950 validation: 0.981600
Iter-1150 loss: 0.9906 validation: 0.982000
Iter-1150 loss: 0.9948 validation: 0.981800
Iter-1200 loss: 0.9901 validation: 0.982000
Iter-1200 loss: 0.9845 validation: 0.983200
Iter-1200 loss: 0.9930 validation: 0.978800
Iter-1200 loss: 0.9924 validation: 0.983000
Iter-1250 loss: 0.9908 validation: 0.981000
Iter-1250 loss: 0.9854 validation: 0.982200
Iter-1250 loss: 0.9924 validation: 0.980600
Iter-1250 loss: 0.9939 validation: 0.981400
Iter-1300 loss: 0.9953 validation: 0.984000
Iter-1300 loss: 0.9893 validation: 0.981000
Iter-1300 loss: 1.0240 validation: 0.979000
Iter-1300 loss: 1.0026 validation: 0.982000
Iter-1350 loss: 1.0100 validation: 0.984000
^CTraceback (most recent call last):
  File "./run_mnist.py", line 159, in <module>
    n_iter=n_iter, print_after=print_after
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 215, in momentum1
    val_acc[k] = util.accuracy(y_val, nn[k].predict(X_val))
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/neuralnet.py", line 79, in predict
    return np.argmax(self.predict_proba(X), axis=1)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/neuralnet.py", line 74, in predict_proba
    score, _ = self.forward(X, False)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/neuralnet.py", line 539, in forward
    hpool1, hpool1_cache = l.maxpool_forward(h1)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py", line 242, in maxpool_forward
    return _pool_forward(X, maxpool, size, stride)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py", line 284, in _pool_forward
    out, pool_cache = pool_fun(X_col)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py", line 238, in maxpool
    out = X_col[max_idx, range(max_idx.size)]
KeyboardInterrupt

wzd@wzd-X455LJ:~/桌面/deepchain2/deepchain/deepchain$ ./run.sh
1 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/loss.py:33: RuntimeWarning: divide by zero encountered in log
  log_like = -np.log(prob[range(m), y_train])
Iter-50 loss: inf validation: 0.099000
Iter-50 loss: inf validation: 0.099000
Iter-50 loss: inf validation: 0.099000
Iter-50 loss: inf validation: 0.099000
/home/wzd/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/home/wzd/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:117: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims)
Iter-100 loss: inf validation: 0.099000
Iter-100 loss: inf validation: 0.099000
Iter-100 loss: inf validation: 0.099000
Iter-100 loss: inf validation: 0.099000
/home/wzd/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:70: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims)
/home/wzd/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:102: RuntimeWarning: overflow encountered in reduce
  arrmean = umr_sum(arr, axis, dtype, keepdims=True)
/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py:90: RuntimeWarning: invalid value encountered in true_divide
  X_norm = (X - mu) / np.sqrt(var + c.eps)
/home/wzd/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce
  return umr_maximum(a, axis, None, out, keepdims)
/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py:33: RuntimeWarning: invalid value encountered in less_equal
  dX[cache <= 0] = 0
/home/wzd/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:112: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py:90: RuntimeWarning: invalid value encountered in subtract
  X_norm = (X - mu) / np.sqrt(var + c.eps)
/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py:143: RuntimeWarning: invalid value encountered in subtract
  X_mu = X - mu
Iter-150 loss: nan validation: 0.095800
Iter-150 loss: nan validation: 0.095800
Iter-150 loss: nan validation: 0.095800
Iter-150 loss: nan validation: 0.095800
/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/regularization.py:6: RuntimeWarning: overflow encountered in multiply
  return .5 * lam * np.sum(W * W)
Iter-200 loss: nan validation: 0.095800
Iter-200 loss: nan validation: 0.095800
Iter-200 loss: nan validation: 0.095800
Iter-200 loss: nan validation: 0.095800
Iter-250 loss: nan validation: 0.095800
Iter-250 loss: nan validation: 0.095800
Iter-250 loss: nan validation: 0.095800
Iter-250 loss: nan validation: 0.095800
/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py:204: RuntimeWarning: overflow encountered in add
  out = W_col @ X_col + b
/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py:223: RuntimeWarning: overflow encountered in add
  velocity[k][layer] = gamma * (velocity[0][layer]+velocity[1][layer]+velocity[2][layer]+velocity[3][layer])+ alpha * (grad[0][layer]+grad[1][layer]+grad[2][layer]+grad[3][layer])
Iter-300 loss: nan validation: 0.095800
/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py:204: RuntimeWarning: invalid value encountered in add
  out = W_col @ X_col + b
Iter-300 loss: nan validation: 0.095800
Iter-300 loss: nan validation: 0.095800
Iter-300 loss: nan validation: 0.095800
Iter-350 loss: nan validation: 0.095800
Iter-350 loss: nan validation: 0.095800
Iter-350 loss: nan validation: 0.095800
Iter-350 loss: nan validation: 0.095800
Iter-400 loss: nan validation: 0.095800
Iter-400 loss: nan validation: 0.095800
Iter-400 loss: nan validation: 0.095800
Iter-400 loss: nan validation: 0.095800
Iter-450 loss: nan validation: 0.095800
Iter-450 loss: nan validation: 0.095800
Iter-450 loss: nan validation: 0.095800
Iter-450 loss: nan validation: 0.095800
Iter-500 loss: nan validation: 0.095800
Iter-500 loss: nan validation: 0.095800
Iter-500 loss: nan validation: 0.095800
Iter-500 loss: nan validation: 0.095800
Iter-550 loss: nan validation: 0.095800
Iter-550 loss: nan validation: 0.095800
Iter-550 loss: nan validation: 0.095800
Iter-550 loss: nan validation: 0.095800
Iter-600 loss: nan validation: 0.095800
Iter-600 loss: nan validation: 0.095800
Iter-600 loss: nan validation: 0.095800
Iter-600 loss: nan validation: 0.095800
Iter-650 loss: nan validation: 0.095800
Iter-650 loss: nan validation: 0.095800
Iter-650 loss: nan validation: 0.095800
Iter-650 loss: nan validation: 0.095800
Iter-700 loss: nan validation: 0.095800
Iter-700 loss: nan validation: 0.095800
Iter-700 loss: nan validation: 0.095800
Iter-700 loss: nan validation: 0.095800
Iter-750 loss: nan validation: 0.095800
Iter-750 loss: nan validation: 0.095800
Iter-750 loss: nan validation: 0.095800
Iter-750 loss: nan validation: 0.095800
Iter-800 loss: nan validation: 0.095800
Iter-800 loss: nan validation: 0.095800
Iter-800 loss: nan validation: 0.095800
Iter-800 loss: nan validation: 0.095800
^CTraceback (most recent call last):
  File "./run_mnist.py", line 159, in <module>
    n_iter=n_iter, print_after=print_after
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 223, in momentum1
    velocity[k][layer] = gamma * (velocity[0][layer]+velocity[1][layer]+velocity[2][layer]+velocity[3][layer])+ alpha * (grad[0][layer]+grad[1][layer]+grad[2][layer]+grad[3][layer])
KeyboardInterrupt

wzd@wzd-X455LJ:~/桌面/deepchain2/deepchain/deepchain$ ./run.sh
1 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.0229 validation: 0.906600
Iter-50 loss: 1.1089 validation: 0.900000
Iter-50 loss: 1.1743 validation: 0.929600
Iter-50 loss: 0.8202 validation: 0.918600
Iter-100 loss: 0.8490 validation: 0.945400
Iter-100 loss: 0.9912 validation: 0.953200
Iter-100 loss: 0.9015 validation: 0.962400
Iter-100 loss: 1.0636 validation: 0.943400
Iter-150 loss: 1.0129 validation: 0.953000
Iter-150 loss: 0.9752 validation: 0.958600
Iter-150 loss: 0.8803 validation: 0.965200
Iter-150 loss: 0.8473 validation: 0.953400
Iter-200 loss: 0.9137 validation: 0.959600
Iter-200 loss: 0.8768 validation: 0.967000
Iter-200 loss: 0.9008 validation: 0.966600
Iter-200 loss: 0.9009 validation: 0.960800
Iter-250 loss: 0.9077 validation: 0.966600
Iter-250 loss: 0.9174 validation: 0.972200
Iter-250 loss: 1.0382 validation: 0.972800
Iter-250 loss: 0.8815 validation: 0.966000
Iter-300 loss: 0.9354 validation: 0.967200
Iter-300 loss: 0.9604 validation: 0.963200
Iter-300 loss: 0.9001 validation: 0.972000
Iter-300 loss: 0.8797 validation: 0.968600
Iter-350 loss: 1.2297 validation: 0.972800
Iter-350 loss: 0.9937 validation: 0.973400
Iter-350 loss: 0.9315 validation: 0.970600
Iter-350 loss: 1.0723 validation: 0.974200
Iter-400 loss: 1.0125 validation: 0.966400
Iter-400 loss: 1.2625 validation: 0.977000
Iter-400 loss: 0.9655 validation: 0.970800
Iter-400 loss: 1.0369 validation: 0.976600
Iter-450 loss: 0.9267 validation: 0.977200
Iter-450 loss: 0.9421 validation: 0.976600
Iter-450 loss: 0.9769 validation: 0.973000
Iter-450 loss: 0.9715 validation: 0.976800
Iter-500 loss: 0.9239 validation: 0.977200
Iter-500 loss: 0.9241 validation: 0.975400
Iter-500 loss: 0.9463 validation: 0.975600
Iter-500 loss: 0.9367 validation: 0.974200
Iter-550 loss: 0.9533 validation: 0.976600
Iter-550 loss: 0.9300 validation: 0.973800
Iter-550 loss: 0.9646 validation: 0.973800
Iter-550 loss: 0.9536 validation: 0.973000
Iter-600 loss: 0.9516 validation: 0.972200
Iter-600 loss: 0.9354 validation: 0.972200
Iter-600 loss: 0.9597 validation: 0.976200
Iter-600 loss: 0.9491 validation: 0.974400
Iter-650 loss: 1.1067 validation: 0.976800
Iter-650 loss: 0.9394 validation: 0.979800
Iter-650 loss: 1.2931 validation: 0.978400
Iter-650 loss: 0.9447 validation: 0.976200
Iter-700 loss: 0.9676 validation: 0.980800
Iter-700 loss: 0.9479 validation: 0.976400
Iter-700 loss: 0.9752 validation: 0.972000
Iter-700 loss: 0.9642 validation: 0.978400
Iter-750 loss: 0.9576 validation: 0.979800
Iter-750 loss: 0.9548 validation: 0.973000
Iter-750 loss: 0.9665 validation: 0.973600
Iter-750 loss: 0.9478 validation: 0.976400
Iter-800 loss: 0.9661 validation: 0.973200
Iter-800 loss: 0.9672 validation: 0.980000
Iter-800 loss: 0.9825 validation: 0.979000
Iter-800 loss: 1.0012 validation: 0.973800
Iter-850 loss: 0.9993 validation: 0.981000
Iter-850 loss: 1.0135 validation: 0.980200
Iter-850 loss: 0.9768 validation: 0.978400
Iter-850 loss: 0.9712 validation: 0.977400
Iter-900 loss: 0.9715 validation: 0.978600
Iter-900 loss: 0.9710 validation: 0.980400
Iter-900 loss: 0.9881 validation: 0.979800
Iter-900 loss: 0.9814 validation: 0.980600
Iter-950 loss: 0.9775 validation: 0.981000
Iter-950 loss: 0.9699 validation: 0.980200
Iter-950 loss: 1.0210 validation: 0.979400
Iter-950 loss: 0.9712 validation: 0.981600
Iter-1000 loss: 0.9784 validation: 0.979400
Iter-1000 loss: 0.9738 validation: 0.980000
Iter-1000 loss: 0.9935 validation: 0.978600
Iter-1000 loss: 0.9702 validation: 0.983200
Iter-1050 loss: 0.9810 validation: 0.979200
Iter-1050 loss: 0.9871 validation: 0.979000
Iter-1050 loss: 0.9920 validation: 0.976400
Iter-1050 loss: 0.9864 validation: 0.980600
Iter-1100 loss: 0.9837 validation: 0.982200
Iter-1100 loss: 0.9794 validation: 0.982200
Iter-1100 loss: 0.9955 validation: 0.980600
Iter-1100 loss: 0.9764 validation: 0.983200
Iter-1150 loss: 0.9992 validation: 0.978600
Iter-1150 loss: 0.9851 validation: 0.983000
Iter-1150 loss: 0.9986 validation: 0.982000
Iter-1150 loss: 0.9864 validation: 0.983200
Iter-1200 loss: 0.9928 validation: 0.981200
Iter-1200 loss: 0.9864 validation: 0.982200
Iter-1200 loss: 1.0024 validation: 0.980600
Iter-1200 loss: 1.0931 validation: 0.975200
Iter-1250 loss: 0.9966 validation: 0.983800
Iter-1250 loss: 0.9939 validation: 0.981400
Iter-1250 loss: 1.0512 validation: 0.979400
Iter-1250 loss: 0.9865 validation: 0.984200
Iter-1300 loss: 0.9987 validation: 0.981600
Iter-1300 loss: 1.0083 validation: 0.982400
Iter-1300 loss: 1.0141 validation: 0.980400
Iter-1300 loss: 0.9890 validation: 0.979800
Iter-1350 loss: 0.9990 validation: 0.984400
Iter-1350 loss: 0.9928 validation: 0.983200
Iter-1350 loss: 1.0085 validation: 0.982200
Iter-1350 loss: 0.9928 validation: 0.984000
Iter-1400 loss: 1.0032 validation: 0.981200
Iter-1400 loss: 0.9978 validation: 0.981400
Iter-1400 loss: 1.0111 validation: 0.981200
Iter-1400 loss: 0.9926 validation: 0.983000
Iter-1450 loss: 1.0029 validation: 0.983400
Iter-1450 loss: 0.9974 validation: 0.984000
Iter-1450 loss: 1.0142 validation: 0.981800
Iter-1450 loss: 1.0005 validation: 0.984600
Iter-1500 loss: 1.0044 validation: 0.981600
Iter-1500 loss: 0.9987 validation: 0.983000
Iter-1500 loss: 1.0290 validation: 0.981800
Iter-1500 loss: 0.9943 validation: 0.982600
Mean accuracy 1: 0.9816, std: 0.0000
Mean accuracy 2: 0.9799, std: 0.0000
Mean accuracy 3: 0.9824, std: 0.0000
Mean accuracy 4: 0.9800, std: 0.0000
Iter-50 loss: 0.9612 validation: 0.936800
Iter-100 loss: 1.0227 validation: 0.929800
Iter-150 loss: 0.9602 validation: 0.944000
Iter-200 loss: 1.0603 validation: 0.965800
^CTraceback (most recent call last):
  File "./run_mnist.py", line 172, in <module>
    n_iter = n_iter,print_after = print_after
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 168, in momentum
    grad, loss = nn.train_step(X_mini, y_mini)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/neuralnet.py", line 69, in train_step
    grad = self.backward(y_pred, y_train, cache)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/neuralnet.py", line 610, in backward
    dh1, dW2, db2 = l.conv_backward(dh2, h2_cache)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py", line 230, in conv_backward
    dX = col2im_indices(dX_col, X.shape, h_filter, w_filter, padding=padding, stride=stride)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/im2col.py", line 50, in col2im_indices
    np.add.at(x_padded, (slice(None), k, i, j), cols_reshaped)
KeyboardInterrupt

wzd@wzd-X455LJ:~/桌面/deepchain2/deepchain/deepchain$ ./run.sh
1 epoch
Traceback (most recent call last):
  File "./run_mnist.py", line 4, in <module>
    from hipsternet.solver import *
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 226
    velocity[k][layer] = gamma*(velocity[k][layer])+alpha*grad[k][layer]    
           ^
IndentationError: expected an indented block
2 epoch
Traceback (most recent call last):
  File "./run_mnist.py", line 4, in <module>
    from hipsternet.solver import *
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 226
    velocity[k][layer] = gamma*(velocity[k][layer])+alpha*grad[k][layer]    
           ^
IndentationError: expected an indented block
3 epoch
Traceback (most recent call last):
  File "./run_mnist.py", line 4, in <module>
    from hipsternet.solver import *
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 226
    velocity[k][layer] = gamma*(velocity[k][layer])+alpha*grad[k][layer]    
           ^
IndentationError: expected an indented block
4 epoch
Traceback (most recent call last):
  File "./run_mnist.py", line 4, in <module>
    from hipsternet.solver import *
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 226
    velocity[k][layer] = gamma*(velocity[k][layer])+alpha*grad[k][layer]    
           ^
IndentationError: expected an indented block
5 epoch
Traceback (most recent call last):
  File "./run_mnist.py", line 4, in <module>
    from hipsternet.solver import *
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 226
    velocity[k][layer] = gamma*(velocity[k][layer])+alpha*grad[k][layer]    
           ^
IndentationError: expected an indented block
6 epoch
Traceback (most recent call last):
  File "./run_mnist.py", line 4, in <module>
    from hipsternet.solver import *
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 226
    velocity[k][layer] = gamma*(velocity[k][layer])+alpha*grad[k][layer]    
           ^
IndentationError: expected an indented block
7 epoch
Traceback (most recent call last):
  File "./run_mnist.py", line 4, in <module>
    from hipsternet.solver import *
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 226
    velocity[k][layer] = gamma*(velocity[k][layer])+alpha*grad[k][layer]    
           ^
IndentationError: expected an indented block
8 epoch
Traceback (most recent call last):
  File "./run_mnist.py", line 4, in <module>
    from hipsternet.solver import *
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 226
    velocity[k][layer] = gamma*(velocity[k][layer])+alpha*grad[k][layer]    
           ^
IndentationError: expected an indented block
9 epoch
Traceback (most recent call last):
  File "./run_mnist.py", line 4, in <module>
    from hipsternet.solver import *
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 226
    velocity[k][layer] = gamma*(velocity[k][layer])+alpha*grad[k][layer]    
           ^
IndentationError: expected an indented block
10 epoch
Traceback (most recent call last):
  File "./run_mnist.py", line 4, in <module>
    from hipsternet.solver import *
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 226
    velocity[k][layer] = gamma*(velocity[k][layer])+alpha*grad[k][layer]    
           ^
IndentationError: expected an indented block
wzd@wzd-X455LJ:~/桌面/deepchain2/deepchain/deepchain$ ./run.sh
1 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 0.9708 validation: 0.914000
Iter-50 loss: 1.0452 validation: 0.904000
Iter-50 loss: 1.3884 validation: 0.927800
Iter-50 loss: 1.0597 validation: 0.772000
Iter-100 loss: 0.9819 validation: 0.946000
Iter-100 loss: 0.9464 validation: 0.953200
Iter-100 loss: 1.1103 validation: 0.969000
Iter-100 loss: 1.1852 validation: 0.942800
Iter-150 loss: 0.9794 validation: 0.953400
Iter-150 loss: 1.0563 validation: 0.968400
Iter-150 loss: 1.0143 validation: 0.970000
Iter-150 loss: 0.9607 validation: 0.957000
Iter-200 loss: 1.1193 validation: 0.965000
Iter-200 loss: 1.0796 validation: 0.962600
Iter-200 loss: 1.0661 validation: 0.972200
Iter-200 loss: 1.0084 validation: 0.968400
Iter-250 loss: 1.0739 validation: 0.961000
Iter-250 loss: 0.9876 validation: 0.977200
Iter-250 loss: 1.0611 validation: 0.973000
Iter-250 loss: 1.1837 validation: 0.975200
Iter-300 loss: 1.1523 validation: 0.972800
Iter-300 loss: 1.0156 validation: 0.977800
Iter-300 loss: 1.0854 validation: 0.970400
Iter-300 loss: 1.1040 validation: 0.980600
Iter-350 loss: 1.0438 validation: 0.971000
Iter-350 loss: 1.0045 validation: 0.979000
Iter-350 loss: 1.1001 validation: 0.957200
Iter-350 loss: 1.1664 validation: 0.976200
Iter-400 loss: 1.0442 validation: 0.978400
Iter-400 loss: 1.0155 validation: 0.982200
Iter-400 loss: 1.0366 validation: 0.978400
Iter-400 loss: 1.0231 validation: 0.978200
Iter-450 loss: 1.1230 validation: 0.980400
Iter-450 loss: 1.0416 validation: 0.977200
Iter-450 loss: 1.1000 validation: 0.983000
Iter-450 loss: 1.0313 validation: 0.980200
Iter-500 loss: 1.0523 validation: 0.972400
Iter-500 loss: 1.0982 validation: 0.980800
Iter-500 loss: 1.2034 validation: 0.977600
Iter-500 loss: 1.0521 validation: 0.975000
Iter-550 loss: 1.1495 validation: 0.972400
Iter-550 loss: 1.1540 validation: 0.983400
Iter-550 loss: 1.0800 validation: 0.981000
Iter-550 loss: 1.0536 validation: 0.981200
Iter-600 loss: 1.0741 validation: 0.974200
Iter-600 loss: 1.1709 validation: 0.978200
Iter-600 loss: 1.0656 validation: 0.967600
Iter-600 loss: 1.1744 validation: 0.981000
Iter-650 loss: 1.0996 validation: 0.977800
Iter-650 loss: 1.0559 validation: 0.978600
Iter-650 loss: 1.0888 validation: 0.977200
Iter-650 loss: 1.0689 validation: 0.983000
Iter-700 loss: 1.0913 validation: 0.982000
Iter-700 loss: 1.0693 validation: 0.979600
Iter-700 loss: 1.0964 validation: 0.979800
Iter-700 loss: 1.1010 validation: 0.976400
Iter-750 loss: 1.0878 validation: 0.971800
Iter-750 loss: 1.1278 validation: 0.983800
Iter-750 loss: 1.2235 validation: 0.985600
Iter-750 loss: 1.1431 validation: 0.986000
Iter-800 loss: 1.1114 validation: 0.980800
Iter-800 loss: 1.0699 validation: 0.983800
Iter-800 loss: 1.1135 validation: 0.984200
Iter-800 loss: 1.0997 validation: 0.982000
Iter-850 loss: 1.1017 validation: 0.985000
Iter-850 loss: 1.0847 validation: 0.984000
Iter-850 loss: 1.1080 validation: 0.983000
Iter-850 loss: 1.1017 validation: 0.984200
Iter-900 loss: 1.1067 validation: 0.982800
Iter-900 loss: 1.0799 validation: 0.985600
Iter-900 loss: 1.1119 validation: 0.986000
Iter-900 loss: 1.1019 validation: 0.983000
Iter-950 loss: 1.1686 validation: 0.982200
Iter-950 loss: 1.0837 validation: 0.986000
Iter-950 loss: 1.1088 validation: 0.979400
Iter-950 loss: 1.1080 validation: 0.984400
Iter-1000 loss: 1.1247 validation: 0.983200
Iter-1000 loss: 1.0883 validation: 0.985000
Iter-1000 loss: 1.1424 validation: 0.984800
Iter-1000 loss: 1.1628 validation: 0.984600
Iter-1050 loss: 1.1229 validation: 0.983000
Iter-1050 loss: 1.0916 validation: 0.982800
Iter-1050 loss: 1.1228 validation: 0.987000
Iter-1050 loss: 1.1151 validation: 0.983800
Iter-1100 loss: 1.1718 validation: 0.984400
Iter-1100 loss: 1.1352 validation: 0.987400
Iter-1100 loss: 1.1375 validation: 0.983800
Iter-1100 loss: 1.1265 validation: 0.980400
Iter-1150 loss: 1.1301 validation: 0.984800
Iter-1150 loss: 1.0998 validation: 0.986200
Iter-1150 loss: 1.1238 validation: 0.987400
Iter-1150 loss: 1.1226 validation: 0.986800
Iter-1200 loss: 1.1392 validation: 0.985000
Iter-1200 loss: 1.1123 validation: 0.985200
Iter-1200 loss: 1.1275 validation: 0.986400
Iter-1200 loss: 1.1314 validation: 0.980800
Iter-1250 loss: 1.1374 validation: 0.985400
Iter-1250 loss: 1.1065 validation: 0.983800
Iter-1250 loss: 1.1317 validation: 0.981600
Iter-1250 loss: 1.1303 validation: 0.985800
Iter-1300 loss: 1.1476 validation: 0.983400
Iter-1300 loss: 1.1116 validation: 0.985600
Iter-1300 loss: 1.1347 validation: 0.986000
Iter-1300 loss: 1.1497 validation: 0.985600
Iter-1350 loss: 1.1510 validation: 0.983800
Iter-1350 loss: 1.1229 validation: 0.987200
Iter-1350 loss: 1.1374 validation: 0.985400
Iter-1350 loss: 1.1336 validation: 0.984600
Iter-1400 loss: 1.1475 validation: 0.986000
Iter-1400 loss: 1.1300 validation: 0.986600
Iter-1400 loss: 1.1394 validation: 0.986400
Iter-1400 loss: 1.1432 validation: 0.985200
Iter-1450 loss: 1.1462 validation: 0.986400
Iter-1450 loss: 1.1210 validation: 0.988200
Iter-1450 loss: 1.1683 validation: 0.986200
Iter-1450 loss: 1.1366 validation: 0.987200
Iter-1500 loss: 1.1478 validation: 0.986600
Iter-1500 loss: 1.1212 validation: 0.987800
Iter-1500 loss: 1.1435 validation: 0.985800
Iter-1500 loss: 1.1384 validation: 0.985000
Mean accuracy 1: 0.9854, std: 0.0000
Mean accuracy 2: 0.9848, std: 0.0000
Mean accuracy 3: 0.9864, std: 0.0000
Mean accuracy 4: 0.9836, std: 0.0000
Iter-50 loss: 1.2335 validation: 0.877800
Iter-100 loss: 1.0374 validation: 0.955400
Iter-150 loss: 1.1831 validation: 0.964600
Iter-200 loss: 1.0046 validation: 0.969000
Iter-250 loss: 1.0353 validation: 0.964800
Iter-300 loss: 1.0550 validation: 0.965400
Iter-350 loss: 1.0528 validation: 0.971600
Iter-400 loss: 1.1743 validation: 0.977000
Iter-450 loss: 1.0953 validation: 0.978600
Iter-500 loss: 1.1734 validation: 0.984000
Iter-550 loss: 1.0907 validation: 0.982200
Iter-600 loss: 1.0955 validation: 0.981400
Iter-650 loss: 1.1912 validation: 0.982200
Iter-700 loss: 1.1468 validation: 0.981600
Iter-750 loss: 1.1586 validation: 0.984000
Iter-800 loss: 1.1220 validation: 0.984800
Iter-850 loss: 1.1326 validation: 0.981000
Iter-900 loss: 1.1344 validation: 0.984400
Iter-950 loss: 1.1553 validation: 0.984200
Iter-1000 loss: 1.1484 validation: 0.983400
Iter-1050 loss: 1.2025 validation: 0.985400
Iter-1100 loss: 1.1638 validation: 0.984000
Iter-1150 loss: 1.1569 validation: 0.984400
Iter-1200 loss: 1.1628 validation: 0.986400
Iter-1250 loss: 1.1618 validation: 0.986000
Iter-1300 loss: 1.1684 validation: 0.984800
Iter-1350 loss: 1.1719 validation: 0.986000
Iter-1400 loss: 1.1710 validation: 0.986800
Iter-1450 loss: 1.1887 validation: 0.984000
Iter-1500 loss: 1.1766 validation: 0.983600
Mean accuracy :0.9839,std :0.0000

Mean accuracy :0.9839,std :0.0000
2 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.0522 validation: 0.900600
Iter-50 loss: 1.3521 validation: 0.847600
Iter-50 loss: 1.0053 validation: 0.919400
Iter-50 loss: 1.0856 validation: 0.904400
Iter-100 loss: 1.0615 validation: 0.957800
Iter-100 loss: 1.1960 validation: 0.955600
Iter-100 loss: 0.9818 validation: 0.960600
Iter-100 loss: 0.9812 validation: 0.950200
Iter-150 loss: 1.0256 validation: 0.960200
Iter-150 loss: 1.0499 validation: 0.967200
Iter-150 loss: 1.0039 validation: 0.967800
Iter-150 loss: 1.0085 validation: 0.967600
Iter-200 loss: 1.0590 validation: 0.964200
Iter-200 loss: 1.0641 validation: 0.963200
Iter-200 loss: 1.1340 validation: 0.970200
Iter-200 loss: 1.0451 validation: 0.962800
Iter-250 loss: 0.9961 validation: 0.973000
Iter-250 loss: 1.0154 validation: 0.977200
Iter-250 loss: 1.0728 validation: 0.978000
Iter-250 loss: 1.0463 validation: 0.976000
Iter-300 loss: 1.2323 validation: 0.972600
Iter-300 loss: 1.0174 validation: 0.976800
Iter-300 loss: 1.0149 validation: 0.971000
Iter-300 loss: 1.2790 validation: 0.968200
Iter-350 loss: 1.0556 validation: 0.973600
Iter-350 loss: 1.0732 validation: 0.979000
Iter-350 loss: 1.0225 validation: 0.973400
Iter-350 loss: 1.0328 validation: 0.969400
Iter-400 loss: 1.0316 validation: 0.972800
Iter-400 loss: 1.0779 validation: 0.977000
Iter-400 loss: 1.0343 validation: 0.975400
Iter-400 loss: 1.0478 validation: 0.975400
Iter-450 loss: 1.0997 validation: 0.981600
Iter-450 loss: 1.0713 validation: 0.975000
Iter-450 loss: 1.1401 validation: 0.980400
Iter-450 loss: 1.1049 validation: 0.982600
Iter-500 loss: 1.0414 validation: 0.978000
Iter-500 loss: 1.0695 validation: 0.979400
Iter-500 loss: 1.0471 validation: 0.981400
Iter-500 loss: 1.0529 validation: 0.979000
Iter-550 loss: 1.1533 validation: 0.979400
Iter-550 loss: 1.0768 validation: 0.978600
Iter-550 loss: 1.0629 validation: 0.979000
Iter-550 loss: 1.0623 validation: 0.979800
Iter-600 loss: 1.0753 validation: 0.979200
Iter-600 loss: 1.0852 validation: 0.983000
Iter-600 loss: 1.1834 validation: 0.983600
Iter-600 loss: 1.0715 validation: 0.985600
Iter-650 loss: 1.1348 validation: 0.977600
Iter-650 loss: 1.0851 validation: 0.979400
Iter-650 loss: 1.0841 validation: 0.980200
Iter-650 loss: 1.0837 validation: 0.982600
Iter-700 loss: 1.0941 validation: 0.982000
Iter-700 loss: 1.2229 validation: 0.982200
Iter-700 loss: 1.0775 validation: 0.982200
Iter-700 loss: 1.1098 validation: 0.980600
Iter-750 loss: 1.1155 validation: 0.981800
Iter-750 loss: 1.1001 validation: 0.984200
Iter-750 loss: 1.0814 validation: 0.983800
Iter-750 loss: 1.1302 validation: 0.983400
Iter-800 loss: 1.1454 validation: 0.979600
Iter-800 loss: 1.1011 validation: 0.980000
Iter-800 loss: 1.0859 validation: 0.984000
Iter-800 loss: 1.1458 validation: 0.978000
Iter-850 loss: 1.1185 validation: 0.980600
Iter-850 loss: 1.1062 validation: 0.983600
Iter-850 loss: 1.0893 validation: 0.984800
Iter-850 loss: 1.1226 validation: 0.982200
Iter-900 loss: 1.1313 validation: 0.977400
Iter-900 loss: 1.1567 validation: 0.983600
Iter-900 loss: 1.0933 validation: 0.983800
Iter-900 loss: 1.1075 validation: 0.984400
Iter-950 loss: 1.1118 validation: 0.981200
Iter-950 loss: 1.1232 validation: 0.982000
Iter-950 loss: 1.1071 validation: 0.984200
Iter-950 loss: 1.1152 validation: 0.984600
Iter-1000 loss: 1.1400 validation: 0.981400
Iter-1000 loss: 1.1341 validation: 0.984600
Iter-1000 loss: 1.1045 validation: 0.982600
Iter-1000 loss: 1.1202 validation: 0.981600
Iter-1050 loss: 1.1275 validation: 0.984000
Iter-1050 loss: 1.1284 validation: 0.984800
Iter-1050 loss: 1.1119 validation: 0.986000
Iter-1050 loss: 1.1245 validation: 0.984800
Iter-1100 loss: 1.1374 validation: 0.982000
Iter-1100 loss: 1.1313 validation: 0.986800
Iter-1100 loss: 1.1125 validation: 0.986000
Iter-1100 loss: 1.1442 validation: 0.986000
Iter-1150 loss: 1.1671 validation: 0.981400
Iter-1150 loss: 1.1307 validation: 0.986800
Iter-1150 loss: 1.2099 validation: 0.985000
Iter-1150 loss: 1.1490 validation: 0.986200
Iter-1200 loss: 1.1408 validation: 0.984000
Iter-1200 loss: 1.1339 validation: 0.984800
Iter-1200 loss: 1.1265 validation: 0.985000
Iter-1200 loss: 1.1382 validation: 0.985600
Iter-1250 loss: 1.1448 validation: 0.982800
Iter-1250 loss: 1.1378 validation: 0.986400
Iter-1250 loss: 1.1210 validation: 0.985600
Iter-1250 loss: 1.1562 validation: 0.985800
Iter-1300 loss: 1.1617 validation: 0.983400
Iter-1300 loss: 1.1424 validation: 0.986800
Iter-1300 loss: 1.1422 validation: 0.987200
Iter-1300 loss: 1.1406 validation: 0.987600
Iter-1350 loss: 1.1550 validation: 0.987200
Iter-1350 loss: 1.1416 validation: 0.984800
Iter-1350 loss: 1.1246 validation: 0.986600
Iter-1350 loss: 1.1389 validation: 0.987400
Iter-1400 loss: 1.1568 validation: 0.985600
Iter-1400 loss: 1.2095 validation: 0.983600
Iter-1400 loss: 1.1277 validation: 0.985200
Iter-1400 loss: 1.1426 validation: 0.986800
Iter-1450 loss: 1.1565 validation: 0.986000
Iter-1450 loss: 1.1523 validation: 0.984200
Iter-1450 loss: 1.1298 validation: 0.986200
Iter-1450 loss: 1.1444 validation: 0.985200
Iter-1500 loss: 1.1554 validation: 0.985000
Iter-1500 loss: 1.1550 validation: 0.984600
Iter-1500 loss: 1.1291 validation: 0.986800
Iter-1500 loss: 1.1485 validation: 0.987000
Mean accuracy 1: 0.9848, std: 0.0000
Mean accuracy 2: 0.9844, std: 0.0000
Mean accuracy 3: 0.9868, std: 0.0000
Mean accuracy 4: 0.9869, std: 0.0000
Iter-50 loss: 0.9226 validation: 0.924800
Iter-100 loss: 0.9826 validation: 0.946400
Iter-150 loss: 1.2020 validation: 0.961000
Iter-200 loss: 1.0583 validation: 0.973200
Iter-250 loss: 1.0022 validation: 0.975400
Iter-300 loss: 1.1959 validation: 0.970800
Iter-350 loss: 1.1668 validation: 0.981000
Iter-400 loss: 1.2060 validation: 0.977600
Iter-450 loss: 1.1598 validation: 0.980200
Iter-500 loss: 1.0574 validation: 0.971200
Iter-550 loss: 1.0844 validation: 0.973400
Iter-600 loss: 1.0959 validation: 0.973200
Iter-650 loss: 1.2835 validation: 0.983600
Iter-700 loss: 1.1185 validation: 0.984800
Iter-750 loss: 1.0993 validation: 0.983800
Iter-800 loss: 1.1079 validation: 0.984600
Iter-850 loss: 1.1130 validation: 0.980200
Iter-900 loss: 1.1184 validation: 0.985600
Iter-950 loss: 1.1506 validation: 0.985400
Iter-1000 loss: 1.1288 validation: 0.986200
Iter-1050 loss: 1.1318 validation: 0.986600
Iter-1100 loss: 1.1386 validation: 0.987200
Iter-1150 loss: 1.1396 validation: 0.987200
Iter-1200 loss: 1.1456 validation: 0.986800
Iter-1250 loss: 1.1615 validation: 0.987200
Iter-1300 loss: 1.2330 validation: 0.987600
Iter-1350 loss: 1.1639 validation: 0.984800
Iter-1400 loss: 1.1582 validation: 0.985600
Iter-1450 loss: 1.1628 validation: 0.986200
Iter-1500 loss: 1.1627 validation: 0.988000
Mean accuracy :0.9855,std :0.0000

Mean accuracy :0.9855,std :0.0000
3 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
^CTraceback (most recent call last):
  File "./run_mnist.py", line 159, in <module>
    n_iter=n_iter, print_after=print_after
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/solver.py", line 211, in momentum1
    grad[k], loss[k] = nn[k].train_step(X_mini[k], y_mini[k])
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/neuralnet.py", line 66, in train_step
    y_pred, cache = self.forward(X_train, train=True)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/neuralnet.py", line 539, in forward
    hpool1, hpool1_cache = l.maxpool_forward(h1)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py", line 242, in maxpool_forward
    return _pool_forward(X, maxpool, size, stride)
  File "/home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/layer.py", line 281, in _pool_forward
    X_reshaped = X.reshape(n * d, 1, h, w)
KeyboardInterrupt

wzd@wzd-X455LJ:~/桌面/deepchain2/deepchain/deepchain$ ./run.sh
1 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.0847 validation: 0.799200
Iter-50 loss: 1.0164 validation: 0.922200
Iter-50 loss: 1.1816 validation: 0.882800
Iter-50 loss: 1.0821 validation: 0.877000
Iter-100 loss: 1.1819 validation: 0.950800
Iter-100 loss: 1.2761 validation: 0.949200
Iter-100 loss: 0.9678 validation: 0.938800
Iter-100 loss: 1.0828 validation: 0.957800
Iter-150 loss: 1.1725 validation: 0.921400
Iter-150 loss: 0.9877 validation: 0.964800
Iter-150 loss: 1.1015 validation: 0.963400
Iter-150 loss: 0.9631 validation: 0.960600
Iter-200 loss: 1.0557 validation: 0.970200
Iter-200 loss: 1.0383 validation: 0.971200
Iter-200 loss: 1.0731 validation: 0.962600
Iter-200 loss: 0.9772 validation: 0.961400
Iter-250 loss: 1.0006 validation: 0.974600
Iter-250 loss: 1.1108 validation: 0.973600
Iter-250 loss: 1.0457 validation: 0.959600
Iter-250 loss: 1.0639 validation: 0.973600
Iter-300 loss: 1.0710 validation: 0.973400
Iter-300 loss: 1.1050 validation: 0.978600
Iter-300 loss: 1.0296 validation: 0.972400
Iter-300 loss: 1.0384 validation: 0.971800
Iter-350 loss: 1.0567 validation: 0.967200
Iter-350 loss: 1.2660 validation: 0.978000
Iter-350 loss: 1.0360 validation: 0.978200
Iter-350 loss: 1.0114 validation: 0.974200
Iter-400 loss: 1.0287 validation: 0.979000
Iter-400 loss: 1.0235 validation: 0.973000
Iter-400 loss: 1.0442 validation: 0.977800
Iter-400 loss: 1.3169 validation: 0.972000
Iter-450 loss: 1.0532 validation: 0.978600
Iter-450 loss: 1.0533 validation: 0.978800
Iter-450 loss: 1.1701 validation: 0.977400
Iter-450 loss: 1.1069 validation: 0.974400
Iter-500 loss: 1.0409 validation: 0.978800
Iter-500 loss: 1.0411 validation: 0.978600
Iter-500 loss: 1.1023 validation: 0.977000
Iter-500 loss: 1.1025 validation: 0.965400
Iter-550 loss: 1.0888 validation: 0.973600
Iter-550 loss: 1.0521 validation: 0.973600
Iter-550 loss: 1.2900 validation: 0.977600
Iter-550 loss: 1.0506 validation: 0.973200
Iter-600 loss: 1.0694 validation: 0.979800
Iter-600 loss: 1.0617 validation: 0.981400
Iter-600 loss: 1.1357 validation: 0.981600
Iter-600 loss: 1.1221 validation: 0.972600
Iter-650 loss: 1.0772 validation: 0.981400
Iter-650 loss: 1.1445 validation: 0.980000
Iter-650 loss: 1.0783 validation: 0.980400
Iter-650 loss: 1.0648 validation: 0.975400
Iter-700 loss: 1.0809 validation: 0.983600
Iter-700 loss: 1.1389 validation: 0.980800
Iter-700 loss: 1.1146 validation: 0.977600
Iter-700 loss: 1.0773 validation: 0.978800
Iter-750 loss: 1.0916 validation: 0.980800
Iter-750 loss: 1.1185 validation: 0.983000
Iter-750 loss: 1.0995 validation: 0.979800
Iter-750 loss: 1.0769 validation: 0.979400
Iter-800 loss: 1.1452 validation: 0.981400
Iter-800 loss: 1.0842 validation: 0.979000
Iter-800 loss: 1.2204 validation: 0.980400
Iter-800 loss: 1.0846 validation: 0.975400
Iter-850 loss: 1.1002 validation: 0.982200
Iter-850 loss: 1.0900 validation: 0.982600
Iter-850 loss: 1.1128 validation: 0.979600
Iter-850 loss: 1.0914 validation: 0.979000
Iter-900 loss: 1.1091 validation: 0.982600
Iter-900 loss: 1.1031 validation: 0.984600
Iter-900 loss: 1.1053 validation: 0.981200
Iter-900 loss: 1.0980 validation: 0.976000
Iter-950 loss: 1.1239 validation: 0.984000
Iter-950 loss: 1.1595 validation: 0.980400
Iter-950 loss: 1.1527 validation: 0.979600
Iter-950 loss: 1.1217 validation: 0.977000
Iter-1000 loss: 1.1294 validation: 0.981400
Iter-1000 loss: 1.2881 validation: 0.979600
Iter-1000 loss: 1.1191 validation: 0.979400
Iter-1000 loss: 1.1314 validation: 0.978400
Iter-1050 loss: 1.1283 validation: 0.986000
Iter-1050 loss: 1.1170 validation: 0.985400
Iter-1050 loss: 1.1276 validation: 0.980400
Iter-1050 loss: 1.1265 validation: 0.981600
Iter-1100 loss: 1.1565 validation: 0.983200
Iter-1100 loss: 1.1189 validation: 0.983600
Iter-1100 loss: 1.1560 validation: 0.980400
Iter-1100 loss: 1.1365 validation: 0.981400
Iter-1150 loss: 1.1307 validation: 0.986000
Iter-1150 loss: 1.1190 validation: 0.984200
Iter-1150 loss: 1.1345 validation: 0.980000
Iter-1150 loss: 1.1791 validation: 0.981600
Iter-1200 loss: 1.1359 validation: 0.983000
Iter-1200 loss: 1.1193 validation: 0.987000
Iter-1200 loss: 1.1339 validation: 0.982600
Iter-1200 loss: 1.1267 validation: 0.984200
Iter-1250 loss: 1.1417 validation: 0.985400
Iter-1250 loss: 1.1262 validation: 0.984800
Iter-1250 loss: 1.1682 validation: 0.984400
Iter-1250 loss: 1.1304 validation: 0.984200
Iter-1300 loss: 1.1373 validation: 0.984800
Iter-1300 loss: 1.1246 validation: 0.984600
Iter-1300 loss: 1.1408 validation: 0.983000
Iter-1300 loss: 1.1319 validation: 0.983400
Iter-1350 loss: 1.1392 validation: 0.985400
Iter-1350 loss: 1.1264 validation: 0.984600
Iter-1350 loss: 1.1429 validation: 0.984200
Iter-1350 loss: 1.1344 validation: 0.984000
Iter-1400 loss: 1.1399 validation: 0.988200
Iter-1400 loss: 1.1331 validation: 0.983600
Iter-1400 loss: 1.1679 validation: 0.984800
Iter-1400 loss: 1.1401 validation: 0.975800
Iter-1450 loss: 1.1420 validation: 0.985200
Iter-1450 loss: 1.1312 validation: 0.986000
Iter-1450 loss: 1.1562 validation: 0.982800
Iter-1450 loss: 1.1391 validation: 0.983200
Iter-1500 loss: 1.1450 validation: 0.985400
Iter-1500 loss: 1.1330 validation: 0.987000
Iter-1500 loss: 1.1531 validation: 0.984400
Iter-1500 loss: 1.1465 validation: 0.982800
Mean accuracy 1: 0.9843, std: 0.0000
Mean accuracy 2: 0.9871, std: 0.0000
Mean accuracy 3: 0.9823, std: 0.0000
Mean accuracy 4: 0.9851, std: 0.0000
Iter-50 loss: 1.1832 validation: 0.829800
Iter-100 loss: 0.9590 validation: 0.926200
Iter-150 loss: 1.0660 validation: 0.962400
Iter-200 loss: 1.0125 validation: 0.965400
Iter-250 loss: 1.0419 validation: 0.975800
Iter-300 loss: 1.0941 validation: 0.967400
Iter-350 loss: 1.0847 validation: 0.969800
Iter-400 loss: 1.0507 validation: 0.976000
Iter-450 loss: 1.0574 validation: 0.977000
Iter-500 loss: 1.0719 validation: 0.981200
Iter-550 loss: 1.0799 validation: 0.975400
Iter-600 loss: 1.0795 validation: 0.982000
Iter-650 loss: 1.1172 validation: 0.980400
Iter-700 loss: 1.0972 validation: 0.984000
Iter-750 loss: 1.1138 validation: 0.981600
Iter-800 loss: 1.1093 validation: 0.982800
Iter-850 loss: 1.1185 validation: 0.982400
Iter-900 loss: 1.1473 validation: 0.985600
Iter-950 loss: 1.1289 validation: 0.983200
Iter-1000 loss: 1.1921 validation: 0.982800
Iter-1050 loss: 1.1286 validation: 0.985600
Iter-1100 loss: 1.1589 validation: 0.980000
Iter-1150 loss: 1.1482 validation: 0.986200
Iter-1200 loss: 1.1437 validation: 0.985200
Iter-1250 loss: 1.1476 validation: 0.986800
Iter-1300 loss: 1.1716 validation: 0.984800
Iter-1350 loss: 1.1517 validation: 0.985600
Iter-1400 loss: 1.1561 validation: 0.984800
Iter-1450 loss: 1.1561 validation: 0.986400
Iter-1500 loss: 1.1603 validation: 0.986000
Mean accuracy :0.9841,std :0.0000

Mean accuracy :0.9841,std :0.0000
2 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 0.9366 validation: 0.925200
Iter-50 loss: 1.5223 validation: 0.919600
Iter-50 loss: 1.1376 validation: 0.936600
Iter-50 loss: 1.2538 validation: 0.881200
Iter-100 loss: 1.1378 validation: 0.937000
Iter-100 loss: 1.3761 validation: 0.940600
Iter-100 loss: 1.2278 validation: 0.940600
Iter-100 loss: 1.0601 validation: 0.949800
Iter-150 loss: 1.0060 validation: 0.954000
Iter-150 loss: 0.9906 validation: 0.953200
Iter-150 loss: 1.0633 validation: 0.961000
Iter-150 loss: 1.2131 validation: 0.963400
Iter-200 loss: 1.0281 validation: 0.959000
Iter-200 loss: 0.9980 validation: 0.963400
Iter-200 loss: 1.0816 validation: 0.925800
Iter-200 loss: 0.9905 validation: 0.952400
Iter-250 loss: 1.0121 validation: 0.967800
Iter-250 loss: 0.9890 validation: 0.972200
Iter-250 loss: 1.1784 validation: 0.965400
Iter-250 loss: 1.0381 validation: 0.962600
Iter-300 loss: 1.0299 validation: 0.969400
Iter-300 loss: 1.0953 validation: 0.970400
Iter-300 loss: 1.0009 validation: 0.974200
Iter-300 loss: 1.0016 validation: 0.972400
Iter-350 loss: 1.0185 validation: 0.977400
Iter-350 loss: 1.0761 validation: 0.974600
Iter-350 loss: 1.0488 validation: 0.977800
Iter-350 loss: 1.1441 validation: 0.972800
Iter-400 loss: 1.1065 validation: 0.981400
Iter-400 loss: 1.1749 validation: 0.952000
Iter-400 loss: 1.1822 validation: 0.975600
Iter-400 loss: 1.0279 validation: 0.977200
Iter-450 loss: 1.0441 validation: 0.983000
Iter-450 loss: 1.0314 validation: 0.976400
Iter-450 loss: 1.2087 validation: 0.972600
Iter-450 loss: 1.0218 validation: 0.974000
Iter-500 loss: 1.0686 validation: 0.981800
Iter-500 loss: 1.0780 validation: 0.967200
Iter-500 loss: 1.1181 validation: 0.978800
Iter-500 loss: 1.0718 validation: 0.976000
Iter-550 loss: 1.0537 validation: 0.979600
Iter-550 loss: 1.0585 validation: 0.979200
Iter-550 loss: 1.0541 validation: 0.975600
Iter-550 loss: 1.1034 validation: 0.966000
Iter-600 loss: 1.0746 validation: 0.981000
Iter-600 loss: 1.1382 validation: 0.981000
Iter-600 loss: 1.0755 validation: 0.979400
Iter-600 loss: 1.0377 validation: 0.974600
Iter-650 loss: 1.0831 validation: 0.982400
Iter-650 loss: 1.0618 validation: 0.981800
Iter-650 loss: 1.1197 validation: 0.978400
Iter-650 loss: 1.0459 validation: 0.978600
Iter-700 loss: 1.0769 validation: 0.983000
Iter-700 loss: 1.1333 validation: 0.981600
Iter-700 loss: 1.0721 validation: 0.980000
Iter-700 loss: 1.0540 validation: 0.978000
Iter-750 loss: 1.1137 validation: 0.981000
Iter-750 loss: 1.1175 validation: 0.979000
Iter-750 loss: 1.2431 validation: 0.982000
Iter-750 loss: 1.1353 validation: 0.974600
Iter-800 loss: 1.0971 validation: 0.980600
Iter-800 loss: 1.1362 validation: 0.977400
Iter-800 loss: 1.0800 validation: 0.975400
Iter-800 loss: 1.0667 validation: 0.979200
Iter-850 loss: 1.0992 validation: 0.982400
Iter-850 loss: 1.1475 validation: 0.981200
Iter-850 loss: 1.1139 validation: 0.980200
Iter-850 loss: 1.0683 validation: 0.978800
Iter-900 loss: 1.2006 validation: 0.981000
Iter-900 loss: 1.1839 validation: 0.976400
Iter-900 loss: 1.0932 validation: 0.981600
Iter-900 loss: 1.2125 validation: 0.979200
Iter-950 loss: 1.1278 validation: 0.985600
Iter-950 loss: 1.1355 validation: 0.981000
Iter-950 loss: 1.0968 validation: 0.980400
Iter-950 loss: 1.0775 validation: 0.982600
Iter-1000 loss: 1.1219 validation: 0.984000
Iter-1000 loss: 1.1085 validation: 0.979800
Iter-1000 loss: 1.1500 validation: 0.978400
Iter-1000 loss: 1.0845 validation: 0.978800
Iter-1050 loss: 1.1606 validation: 0.984400
Iter-1050 loss: 1.1112 validation: 0.984200
Iter-1050 loss: 1.1218 validation: 0.982600
Iter-1050 loss: 1.0833 validation: 0.982000
Iter-1100 loss: 1.1265 validation: 0.984000
Iter-1100 loss: 1.1165 validation: 0.984400
Iter-1100 loss: 1.1292 validation: 0.978000
Iter-1100 loss: 1.1199 validation: 0.981400
Iter-1150 loss: 1.1307 validation: 0.985400
Iter-1150 loss: 1.1372 validation: 0.983800
Iter-1150 loss: 1.1438 validation: 0.975800
Iter-1150 loss: 1.0893 validation: 0.981800
Iter-1200 loss: 1.1607 validation: 0.983200
Iter-1200 loss: 1.1248 validation: 0.983200
Iter-1200 loss: 1.1297 validation: 0.984600
Iter-1200 loss: 1.1602 validation: 0.981600
Iter-1250 loss: 1.1520 validation: 0.985800
Iter-1250 loss: 1.1252 validation: 0.982800
Iter-1250 loss: 1.1401 validation: 0.983400
Iter-1250 loss: 1.0917 validation: 0.982800
Iter-1300 loss: 1.1427 validation: 0.987800
Iter-1300 loss: 1.1491 validation: 0.980000
Iter-1300 loss: 1.1623 validation: 0.979800
Iter-1300 loss: 1.0970 validation: 0.979800
Iter-1350 loss: 1.1407 validation: 0.985800
Iter-1350 loss: 1.1373 validation: 0.981400
Iter-1350 loss: 1.2359 validation: 0.980400
Iter-1350 loss: 1.1079 validation: 0.982000
Iter-1400 loss: 1.1416 validation: 0.985400
Iter-1400 loss: 1.1449 validation: 0.983200
Iter-1400 loss: 1.1489 validation: 0.985000
Iter-1400 loss: 1.1073 validation: 0.980400
Iter-1450 loss: 1.1435 validation: 0.984800
Iter-1450 loss: 1.1447 validation: 0.985200
Iter-1450 loss: 1.1692 validation: 0.983200
Iter-1450 loss: 1.1542 validation: 0.978800
Iter-1500 loss: 1.1968 validation: 0.985800
Iter-1500 loss: 1.1641 validation: 0.984000
Iter-1500 loss: 1.1536 validation: 0.981400
Iter-1500 loss: 1.1110 validation: 0.977200
Mean accuracy 1: 0.9843, std: 0.0000
Mean accuracy 2: 0.9838, std: 0.0000
Mean accuracy 3: 0.9807, std: 0.0000
Mean accuracy 4: 0.9698, std: 0.0000
Iter-50 loss: 1.1796 validation: 0.866000
Iter-100 loss: 0.9597 validation: 0.961400
Iter-150 loss: 1.0553 validation: 0.965400
Iter-200 loss: 0.9758 validation: 0.961800
Iter-250 loss: 1.0569 validation: 0.967800
Iter-300 loss: 1.0255 validation: 0.970200
Iter-350 loss: 1.0166 validation: 0.975400
Iter-400 loss: 1.0818 validation: 0.977200
Iter-450 loss: 1.0503 validation: 0.981600
Iter-500 loss: 1.0633 validation: 0.978200
Iter-550 loss: 1.0911 validation: 0.970000
Iter-600 loss: 1.0852 validation: 0.975800
Iter-650 loss: 1.0936 validation: 0.983800
Iter-700 loss: 1.0892 validation: 0.985800
Iter-750 loss: 1.0799 validation: 0.980000
Iter-800 loss: 1.1005 validation: 0.980000
Iter-850 loss: 1.0965 validation: 0.983600
Iter-900 loss: 1.0997 validation: 0.983400
Iter-950 loss: 1.0994 validation: 0.986400
Iter-1000 loss: 1.1026 validation: 0.984000
Iter-1050 loss: 1.1081 validation: 0.983200
Iter-1100 loss: 1.1195 validation: 0.983400
Iter-1150 loss: 1.1184 validation: 0.982600
Iter-1200 loss: 1.1199 validation: 0.985400
Iter-1250 loss: 1.1267 validation: 0.986000
Iter-1300 loss: 1.1279 validation: 0.984200
Iter-1350 loss: 1.1316 validation: 0.982400
Iter-1400 loss: 1.1393 validation: 0.984600
Iter-1450 loss: 1.1371 validation: 0.985200
Iter-1500 loss: 1.1393 validation: 0.985000
Mean accuracy :0.9848,std :0.0000

Mean accuracy :0.9848,std :0.0000
3 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.0185 validation: 0.896400
Iter-50 loss: 1.0777 validation: 0.923800
Iter-50 loss: 1.4416 validation: 0.894000
Iter-50 loss: 1.1794 validation: 0.928600
Iter-100 loss: 1.0269 validation: 0.957800
Iter-100 loss: 0.9585 validation: 0.944400
Iter-100 loss: 1.0033 validation: 0.950800
Iter-100 loss: 1.0730 validation: 0.945800
Iter-150 loss: 1.0533 validation: 0.955200
Iter-150 loss: 1.0812 validation: 0.966400
Iter-150 loss: 1.0943 validation: 0.963000
Iter-150 loss: 1.0026 validation: 0.951000
Iter-200 loss: 1.0967 validation: 0.965800
Iter-200 loss: 1.0839 validation: 0.960800
Iter-200 loss: 1.0263 validation: 0.968000
Iter-200 loss: 1.0539 validation: 0.964800
Iter-250 loss: 1.1011 validation: 0.969800
Iter-250 loss: 1.0449 validation: 0.966400
Iter-250 loss: 1.0047 validation: 0.973200
Iter-250 loss: 1.0571 validation: 0.948200
Iter-300 loss: 1.0720 validation: 0.969400
Iter-300 loss: 1.0418 validation: 0.970600
Iter-300 loss: 1.0947 validation: 0.961800
Iter-300 loss: 1.0558 validation: 0.965000
Iter-350 loss: 1.0113 validation: 0.969800
Iter-350 loss: 1.0349 validation: 0.971200
Iter-350 loss: 1.0969 validation: 0.971000
Iter-350 loss: 1.0684 validation: 0.974800
Iter-400 loss: 1.0618 validation: 0.973600
Iter-400 loss: 1.0455 validation: 0.977200
Iter-400 loss: 1.2519 validation: 0.972800
Iter-400 loss: 1.0998 validation: 0.975400
Iter-450 loss: 1.0609 validation: 0.976800
Iter-450 loss: 1.0984 validation: 0.977600
Iter-450 loss: 1.2389 validation: 0.967200
Iter-450 loss: 1.0830 validation: 0.966200
Iter-500 loss: 1.1591 validation: 0.975600
Iter-500 loss: 1.0602 validation: 0.974600
Iter-500 loss: 1.1422 validation: 0.960400
Iter-500 loss: 1.0745 validation: 0.977200
Iter-550 loss: 1.0691 validation: 0.978800
Iter-550 loss: 1.0945 validation: 0.976200
Iter-550 loss: 1.1472 validation: 0.976200
Iter-550 loss: 1.1606 validation: 0.979200
Iter-600 loss: 1.1457 validation: 0.977400
Iter-600 loss: 1.0505 validation: 0.979800
Iter-600 loss: 1.1234 validation: 0.977600
Iter-600 loss: 1.0831 validation: 0.980000
Iter-650 loss: 1.0819 validation: 0.982200
Iter-650 loss: 1.0566 validation: 0.981800
Iter-650 loss: 1.1161 validation: 0.978200
Iter-650 loss: 1.1030 validation: 0.978800
Iter-700 loss: 1.1076 validation: 0.981400
Iter-700 loss: 1.0684 validation: 0.978600
Iter-700 loss: 1.1058 validation: 0.983200
Iter-700 loss: 1.0979 validation: 0.978600
Iter-750 loss: 1.1069 validation: 0.982400
Iter-750 loss: 1.0850 validation: 0.978200
Iter-750 loss: 1.1055 validation: 0.981200
Iter-750 loss: 1.1096 validation: 0.975000
Iter-800 loss: 1.0996 validation: 0.979800
Iter-800 loss: 1.1120 validation: 0.981600
Iter-800 loss: 1.2312 validation: 0.982600
Iter-800 loss: 1.1126 validation: 0.979800
Iter-850 loss: 1.1086 validation: 0.977000
Iter-850 loss: 1.1717 validation: 0.977800
Iter-850 loss: 1.1207 validation: 0.980200
Iter-850 loss: 1.1235 validation: 0.979600
Iter-900 loss: 1.1260 validation: 0.980200
Iter-900 loss: 1.0939 validation: 0.972400
Iter-900 loss: 1.1319 validation: 0.978200
Iter-900 loss: 1.1220 validation: 0.976000
Iter-950 loss: 1.1129 validation: 0.982600
Iter-950 loss: 1.1046 validation: 0.982200
Iter-950 loss: 1.1263 validation: 0.980200
Iter-950 loss: 1.1304 validation: 0.977600
Iter-1000 loss: 1.1077 validation: 0.984200
Iter-1000 loss: 1.1154 validation: 0.983800
Iter-1000 loss: 1.1278 validation: 0.981600
Iter-1000 loss: 1.1331 validation: 0.978600
Iter-1050 loss: 1.1101 validation: 0.983000
Iter-1050 loss: 1.1108 validation: 0.985000
Iter-1050 loss: 1.1317 validation: 0.981200
Iter-1050 loss: 1.1394 validation: 0.978400
Iter-1100 loss: 1.1285 validation: 0.985200
Iter-1100 loss: 1.1076 validation: 0.983400
Iter-1100 loss: 1.1325 validation: 0.984800
Iter-1100 loss: 1.1461 validation: 0.976200
Iter-1150 loss: 1.1194 validation: 0.983400
Iter-1150 loss: 1.1467 validation: 0.983000
Iter-1150 loss: 1.1392 validation: 0.981600
Iter-1150 loss: 1.1611 validation: 0.979600
Iter-1200 loss: 1.1411 validation: 0.984600
Iter-1200 loss: 1.1150 validation: 0.983800
Iter-1200 loss: 1.2127 validation: 0.983600
Iter-1200 loss: 1.1583 validation: 0.981800
Iter-1250 loss: 1.1278 validation: 0.985600
Iter-1250 loss: 1.1231 validation: 0.982200
Iter-1250 loss: 1.1986 validation: 0.983800
Iter-1250 loss: 1.1570 validation: 0.981200
Iter-1300 loss: 1.1404 validation: 0.985800
Iter-1300 loss: 1.1875 validation: 0.983400
Iter-1300 loss: 1.1514 validation: 0.984200
Iter-1300 loss: 1.1631 validation: 0.981800
Iter-1350 loss: 1.1314 validation: 0.983400
Iter-1350 loss: 1.1290 validation: 0.982000
Iter-1350 loss: 1.1588 validation: 0.981400
Iter-1350 loss: 1.1614 validation: 0.981600
Iter-1400 loss: 1.1344 validation: 0.979400
Iter-1400 loss: 1.1314 validation: 0.982400
Iter-1400 loss: 1.1590 validation: 0.981600
Iter-1400 loss: 1.1653 validation: 0.979600
Iter-1450 loss: 1.1522 validation: 0.977600
Iter-1450 loss: 1.1341 validation: 0.980600
Iter-1450 loss: 1.1620 validation: 0.982600
Iter-1450 loss: 1.1677 validation: 0.982000
Iter-1500 loss: 1.2006 validation: 0.982200
Iter-1500 loss: 1.1343 validation: 0.985200
Iter-1500 loss: 1.1671 validation: 0.982000
Iter-1500 loss: 1.2162 validation: 0.981200
Mean accuracy 1: 0.9837, std: 0.0000
Mean accuracy 2: 0.9851, std: 0.0000
Mean accuracy 3: 0.9818, std: 0.0000
Mean accuracy 4: 0.9813, std: 0.0000
Iter-50 loss: 1.0473 validation: 0.904400
Iter-100 loss: 1.0875 validation: 0.957000
Iter-150 loss: 0.9988 validation: 0.968600
Iter-200 loss: 1.1716 validation: 0.970200
Iter-250 loss: 1.1041 validation: 0.970800
Iter-300 loss: 1.0612 validation: 0.972200
Iter-350 loss: 1.0574 validation: 0.955200
Iter-400 loss: 1.0559 validation: 0.971200
Iter-450 loss: 1.0652 validation: 0.973800
Iter-500 loss: 1.0692 validation: 0.978600
Iter-550 loss: 1.1345 validation: 0.973800
Iter-600 loss: 1.1032 validation: 0.979000
Iter-650 loss: 1.1494 validation: 0.977200
Iter-700 loss: 1.1444 validation: 0.971400
Iter-750 loss: 1.1444 validation: 0.982400
Iter-800 loss: 1.1416 validation: 0.979200
Iter-850 loss: 1.1309 validation: 0.981800
Iter-900 loss: 1.1432 validation: 0.981600
Iter-950 loss: 1.1393 validation: 0.980000
Iter-1000 loss: 1.1537 validation: 0.981000
Iter-1050 loss: 1.1676 validation: 0.981600
Iter-1100 loss: 1.1558 validation: 0.978600
Iter-1150 loss: 1.1639 validation: 0.982400
Iter-1200 loss: 1.1651 validation: 0.982800
Iter-1250 loss: 1.1679 validation: 0.982400
Iter-1300 loss: 1.1736 validation: 0.980400
Iter-1350 loss: 1.1759 validation: 0.983000
Iter-1400 loss: 1.1806 validation: 0.983200
Iter-1450 loss: 1.1802 validation: 0.984000
Iter-1500 loss: 1.1833 validation: 0.981000
Mean accuracy :0.9818,std :0.0000

Mean accuracy :0.9818,std :0.0000
4 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.0070 validation: 0.930600
Iter-50 loss: 1.0539 validation: 0.861400
Iter-50 loss: 1.1228 validation: 0.869800
Iter-50 loss: 1.0148 validation: 0.884600
Iter-100 loss: 1.0067 validation: 0.955600
Iter-100 loss: 1.1040 validation: 0.948400
Iter-100 loss: 0.9388 validation: 0.956600
Iter-100 loss: 1.0074 validation: 0.954200
Iter-150 loss: 1.2934 validation: 0.963800
Iter-150 loss: 0.9775 validation: 0.957800
Iter-150 loss: 1.0640 validation: 0.962000
Iter-150 loss: 1.0889 validation: 0.964200
Iter-200 loss: 1.0583 validation: 0.946800
Iter-200 loss: 1.0131 validation: 0.964000
Iter-200 loss: 1.0546 validation: 0.968000
Iter-200 loss: 1.0242 validation: 0.961000
Iter-250 loss: 1.0204 validation: 0.975200
Iter-250 loss: 1.0062 validation: 0.970200
Iter-250 loss: 1.0957 validation: 0.973400
Iter-250 loss: 1.0227 validation: 0.967800
Iter-300 loss: 1.0269 validation: 0.963600
Iter-300 loss: 1.0119 validation: 0.972200
Iter-300 loss: 1.0291 validation: 0.976800
Iter-300 loss: 1.0103 validation: 0.973200
Iter-350 loss: 1.0412 validation: 0.977800
Iter-350 loss: 1.0780 validation: 0.973000
Iter-350 loss: 1.0136 validation: 0.978200
Iter-350 loss: 1.0242 validation: 0.968000
Iter-400 loss: 1.0386 validation: 0.975400
Iter-400 loss: 1.0484 validation: 0.973000
Iter-400 loss: 1.0512 validation: 0.978600
Iter-400 loss: 1.0461 validation: 0.974400
Iter-450 loss: 1.0605 validation: 0.972800
Iter-450 loss: 1.0604 validation: 0.973800
Iter-450 loss: 1.0409 validation: 0.979400
Iter-450 loss: 1.0531 validation: 0.980200
Iter-500 loss: 1.0765 validation: 0.972000
Iter-500 loss: 1.1166 validation: 0.973800
Iter-500 loss: 1.0819 validation: 0.977600
Iter-500 loss: 1.2097 validation: 0.977800
Iter-550 loss: 1.0693 validation: 0.975200
Iter-550 loss: 1.0605 validation: 0.980600
Iter-550 loss: 1.0728 validation: 0.979000
Iter-550 loss: 1.4300 validation: 0.980200
Iter-600 loss: 1.1653 validation: 0.977400
Iter-600 loss: 1.0645 validation: 0.980800
Iter-600 loss: 1.0544 validation: 0.980000
Iter-600 loss: 1.0599 validation: 0.982800
Iter-650 loss: 1.0861 validation: 0.975200
Iter-650 loss: 1.0788 validation: 0.981800
Iter-650 loss: 1.0623 validation: 0.982400
Iter-650 loss: 1.0662 validation: 0.982600
Iter-700 loss: 1.0964 validation: 0.980600
Iter-700 loss: 1.0831 validation: 0.982800
Iter-700 loss: 1.0975 validation: 0.981200
Iter-700 loss: 1.0641 validation: 0.976200
Iter-750 loss: 1.0983 validation: 0.978000
Iter-750 loss: 1.0844 validation: 0.980600
Iter-750 loss: 1.0727 validation: 0.980600
Iter-750 loss: 1.1408 validation: 0.978600
Iter-800 loss: 1.1096 validation: 0.974800
Iter-800 loss: 1.1141 validation: 0.977000
Iter-800 loss: 1.0918 validation: 0.976000
Iter-800 loss: 1.0807 validation: 0.981600
Iter-850 loss: 1.1304 validation: 0.981200
Iter-850 loss: 1.1005 validation: 0.981000
Iter-850 loss: 1.2155 validation: 0.979400
Iter-850 loss: 1.0882 validation: 0.981000
Iter-900 loss: 1.1672 validation: 0.985800
Iter-900 loss: 1.1236 validation: 0.981800
Iter-900 loss: 1.0996 validation: 0.982200
Iter-900 loss: 1.1025 validation: 0.979600
Iter-950 loss: 1.1406 validation: 0.985200
Iter-950 loss: 1.1109 validation: 0.984600
Iter-950 loss: 1.0999 validation: 0.979800
Iter-950 loss: 1.1251 validation: 0.982800
Iter-1000 loss: 1.1237 validation: 0.986400
Iter-1000 loss: 1.1262 validation: 0.982000
Iter-1000 loss: 1.1118 validation: 0.973600
Iter-1000 loss: 1.1016 validation: 0.981600
Iter-1050 loss: 1.1322 validation: 0.983400
Iter-1050 loss: 1.1220 validation: 0.982600
Iter-1050 loss: 1.1474 validation: 0.977600
Iter-1050 loss: 1.1030 validation: 0.983800
Iter-1100 loss: 1.1306 validation: 0.984200
Iter-1100 loss: 1.1234 validation: 0.985400
Iter-1100 loss: 1.1639 validation: 0.975600
Iter-1100 loss: 1.1096 validation: 0.981800
Iter-1150 loss: 1.1362 validation: 0.985400
Iter-1150 loss: 1.1280 validation: 0.982600
Iter-1150 loss: 1.1472 validation: 0.982800
Iter-1150 loss: 1.1098 validation: 0.982400
Iter-1200 loss: 1.1389 validation: 0.986000
Iter-1200 loss: 1.1336 validation: 0.980000
Iter-1200 loss: 1.1473 validation: 0.983800
Iter-1200 loss: 1.1149 validation: 0.981000
Iter-1250 loss: 1.1404 validation: 0.985200
Iter-1250 loss: 1.1512 validation: 0.980000
Iter-1250 loss: 1.1407 validation: 0.983400
Iter-1250 loss: 1.1278 validation: 0.984200
Iter-1300 loss: 1.1733 validation: 0.983800
Iter-1300 loss: 1.1460 validation: 0.982800
Iter-1300 loss: 1.1427 validation: 0.980000
Iter-1300 loss: 1.1177 validation: 0.984600
Iter-1350 loss: 1.1457 validation: 0.983400
Iter-1350 loss: 1.1518 validation: 0.981400
Iter-1350 loss: 1.1455 validation: 0.985000
Iter-1350 loss: 1.1215 validation: 0.984400
Iter-1400 loss: 1.1635 validation: 0.985400
Iter-1400 loss: 1.1565 validation: 0.982000
Iter-1400 loss: 1.1657 validation: 0.980800
Iter-1400 loss: 1.1222 validation: 0.980800
Iter-1450 loss: 1.1496 validation: 0.986200
Iter-1450 loss: 1.1745 validation: 0.979000
Iter-1450 loss: 1.1657 validation: 0.984400
Iter-1450 loss: 1.1410 validation: 0.983200
Iter-1500 loss: 1.1519 validation: 0.986200
Iter-1500 loss: 1.1928 validation: 0.982400
Iter-1500 loss: 1.1567 validation: 0.985200
Iter-1500 loss: 1.1271 validation: 0.984600
Mean accuracy 1: 0.9829, std: 0.0000
Mean accuracy 2: 0.9837, std: 0.0000
Mean accuracy 3: 0.9849, std: 0.0000
Mean accuracy 4: 0.9839, std: 0.0000
Iter-50 loss: 1.0721 validation: 0.933400
Iter-100 loss: 1.0719 validation: 0.963800
Iter-150 loss: 1.0137 validation: 0.967200
Iter-200 loss: 1.0743 validation: 0.972400
Iter-250 loss: 1.1854 validation: 0.976800
Iter-300 loss: 1.1627 validation: 0.973600
Iter-350 loss: 1.1219 validation: 0.977400
Iter-400 loss: 1.0791 validation: 0.979400
Iter-450 loss: 1.1309 validation: 0.981600
Iter-500 loss: 1.1589 validation: 0.975600
Iter-550 loss: 1.1341 validation: 0.980400
Iter-600 loss: 1.1346 validation: 0.978000
Iter-650 loss: 1.1017 validation: 0.980800
Iter-700 loss: 1.1040 validation: 0.979600
Iter-750 loss: 1.1287 validation: 0.979800
Iter-800 loss: 1.1190 validation: 0.981800
Iter-850 loss: 1.1238 validation: 0.979400
Iter-900 loss: 1.1259 validation: 0.987000
Iter-950 loss: 1.1538 validation: 0.985000
Iter-1000 loss: 1.1472 validation: 0.984800
Iter-1050 loss: 1.1371 validation: 0.981200
Iter-1100 loss: 1.1466 validation: 0.984600
Iter-1150 loss: 1.1445 validation: 0.982000
Iter-1200 loss: 1.1539 validation: 0.984000
Iter-1250 loss: 1.1549 validation: 0.982600
Iter-1300 loss: 1.1783 validation: 0.983800
Iter-1350 loss: 1.1617 validation: 0.983400
Iter-1400 loss: 1.1740 validation: 0.982600
Iter-1450 loss: 1.1702 validation: 0.984400
Iter-1500 loss: 1.1737 validation: 0.983200
Mean accuracy :0.9789,std :0.0000

Mean accuracy :0.9789,std :0.0000
5 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.3298 validation: 0.863600
Iter-50 loss: 1.2539 validation: 0.912800
Iter-50 loss: 1.3709 validation: 0.863600
Iter-50 loss: 1.2379 validation: 0.801200
Iter-100 loss: 1.2956 validation: 0.953000
Iter-100 loss: 1.1262 validation: 0.960800
Iter-100 loss: 1.1092 validation: 0.958400
Iter-100 loss: 1.0847 validation: 0.920000
Iter-150 loss: 1.0057 validation: 0.944600
Iter-150 loss: 1.0713 validation: 0.940200
Iter-150 loss: 1.0377 validation: 0.964000
Iter-150 loss: 1.0982 validation: 0.962400
Iter-200 loss: 1.1651 validation: 0.965400
Iter-200 loss: 1.0356 validation: 0.963600
Iter-200 loss: 1.0952 validation: 0.972200
Iter-200 loss: 1.0102 validation: 0.959600
Iter-250 loss: 1.0443 validation: 0.958800
Iter-250 loss: 1.0786 validation: 0.965200
Iter-250 loss: 1.0344 validation: 0.966200
Iter-250 loss: 1.1827 validation: 0.965400
Iter-300 loss: 1.0388 validation: 0.972000
Iter-300 loss: 1.0396 validation: 0.975800
Iter-300 loss: 1.0157 validation: 0.975200
Iter-300 loss: 0.9995 validation: 0.973000
Iter-350 loss: 1.1857 validation: 0.977200
Iter-350 loss: 1.0906 validation: 0.975600
Iter-350 loss: 1.0541 validation: 0.975200
Iter-350 loss: 0.9919 validation: 0.971800
Iter-400 loss: 1.0709 validation: 0.975200
Iter-400 loss: 1.2719 validation: 0.984000
Iter-400 loss: 1.0803 validation: 0.979600
Iter-400 loss: 1.1368 validation: 0.974000
Iter-450 loss: 1.0867 validation: 0.979400
Iter-450 loss: 1.0963 validation: 0.978000
Iter-450 loss: 1.0403 validation: 0.978400
Iter-450 loss: 1.1178 validation: 0.977600
Iter-500 loss: 1.1055 validation: 0.976400
Iter-500 loss: 1.0883 validation: 0.979800
Iter-500 loss: 1.0522 validation: 0.979400
Iter-500 loss: 1.0385 validation: 0.976800
Iter-550 loss: 1.1593 validation: 0.979800
Iter-550 loss: 1.1028 validation: 0.978800
Iter-550 loss: 1.0939 validation: 0.973600
Iter-550 loss: 1.0457 validation: 0.980200
Iter-600 loss: 1.0920 validation: 0.978800
Iter-600 loss: 1.0918 validation: 0.980600
Iter-600 loss: 1.0893 validation: 0.971200
Iter-600 loss: 1.3052 validation: 0.978000
Iter-650 loss: 1.2122 validation: 0.972800
Iter-650 loss: 1.2406 validation: 0.979800
Iter-650 loss: 1.1035 validation: 0.976800
Iter-650 loss: 1.0349 validation: 0.973600
Iter-700 loss: 1.1701 validation: 0.975400
Iter-700 loss: 1.1255 validation: 0.983000
Iter-700 loss: 1.0927 validation: 0.981600
Iter-700 loss: 1.0441 validation: 0.973200
Iter-750 loss: 1.2085 validation: 0.983000
Iter-750 loss: 1.0922 validation: 0.982400
Iter-750 loss: 1.0906 validation: 0.980200
Iter-750 loss: 1.0483 validation: 0.979200
Iter-800 loss: 1.3157 validation: 0.974000
Iter-800 loss: 1.1012 validation: 0.983000
Iter-800 loss: 1.1011 validation: 0.984200
Iter-800 loss: 1.0599 validation: 0.978400
Iter-850 loss: 1.1469 validation: 0.977400
Iter-850 loss: 1.1059 validation: 0.981600
Iter-850 loss: 1.1173 validation: 0.976200
Iter-850 loss: 1.0995 validation: 0.979000
Iter-900 loss: 1.1475 validation: 0.983200
Iter-900 loss: 1.1158 validation: 0.983800
Iter-900 loss: 1.1096 validation: 0.980600
Iter-900 loss: 1.0673 validation: 0.981400
Iter-950 loss: 1.1554 validation: 0.982400
Iter-950 loss: 1.1330 validation: 0.984000
Iter-950 loss: 1.1203 validation: 0.983600
Iter-950 loss: 1.0902 validation: 0.982000
Iter-1000 loss: 1.1872 validation: 0.983400
Iter-1000 loss: 1.1202 validation: 0.983600
Iter-1000 loss: 1.1169 validation: 0.980000
Iter-1000 loss: 1.0785 validation: 0.980200
Iter-1050 loss: 1.1608 validation: 0.982000
Iter-1050 loss: 1.1225 validation: 0.984600
Iter-1050 loss: 1.1299 validation: 0.980800
Iter-1050 loss: 1.0846 validation: 0.980800
Iter-1100 loss: 1.1681 validation: 0.982200
Iter-1100 loss: 1.1329 validation: 0.984400
Iter-1100 loss: 1.1362 validation: 0.974400
Iter-1100 loss: 1.0857 validation: 0.979000
Iter-1150 loss: 1.1666 validation: 0.985000
Iter-1150 loss: 1.1327 validation: 0.984000
Iter-1150 loss: 1.1334 validation: 0.979000
Iter-1150 loss: 1.1120 validation: 0.982400
Iter-1200 loss: 1.1679 validation: 0.983800
Iter-1200 loss: 1.1333 validation: 0.981200
Iter-1200 loss: 1.1405 validation: 0.982400
Iter-1200 loss: 1.0905 validation: 0.977800
Iter-1250 loss: 1.1711 validation: 0.983600
Iter-1250 loss: 1.1352 validation: 0.982800
Iter-1250 loss: 1.1498 validation: 0.984400
Iter-1250 loss: 1.0929 validation: 0.982400
Iter-1300 loss: 1.1746 validation: 0.983800
Iter-1300 loss: 1.1411 validation: 0.984000
Iter-1300 loss: 1.1464 validation: 0.983000
Iter-1300 loss: 1.0964 validation: 0.981400
Iter-1350 loss: 1.1743 validation: 0.984400
Iter-1350 loss: 1.1406 validation: 0.984600
Iter-1350 loss: 1.1626 validation: 0.982000
Iter-1350 loss: 1.1059 validation: 0.983800
Iter-1400 loss: 1.1794 validation: 0.985400
Iter-1400 loss: 1.1427 validation: 0.984200
Iter-1400 loss: 1.1544 validation: 0.982000
Iter-1400 loss: 1.1451 validation: 0.983000
Iter-1450 loss: 1.1812 validation: 0.984400
Iter-1450 loss: 1.1459 validation: 0.985000
Iter-1450 loss: 1.1758 validation: 0.983800
Iter-1450 loss: 1.1089 validation: 0.983400
Iter-1500 loss: 1.1854 validation: 0.986400
Iter-1500 loss: 1.1461 validation: 0.984200
Iter-1500 loss: 1.1594 validation: 0.985400
Iter-1500 loss: 1.1089 validation: 0.983600
Mean accuracy 1: 0.9848, std: 0.0000
Mean accuracy 2: 0.9856, std: 0.0000
Mean accuracy 3: 0.9857, std: 0.0000
Mean accuracy 4: 0.9854, std: 0.0000
Iter-50 loss: 1.1575 validation: 0.840800
Iter-100 loss: 1.0776 validation: 0.951400
Iter-150 loss: 1.0031 validation: 0.960200
Iter-200 loss: 0.9928 validation: 0.968200
Iter-250 loss: 1.0626 validation: 0.968000
Iter-300 loss: 1.0126 validation: 0.969200
Iter-350 loss: 1.0402 validation: 0.979800
Iter-400 loss: 1.1200 validation: 0.977800
Iter-450 loss: 1.0715 validation: 0.978600
Iter-500 loss: 1.0911 validation: 0.975600
Iter-550 loss: 1.0653 validation: 0.974800
Iter-600 loss: 1.0706 validation: 0.981600
Iter-650 loss: 1.2888 validation: 0.981800
Iter-700 loss: 1.1003 validation: 0.983400
Iter-750 loss: 1.1135 validation: 0.981600
Iter-800 loss: 1.0995 validation: 0.983600
Iter-850 loss: 1.1066 validation: 0.983600
Iter-900 loss: 1.1120 validation: 0.985200
Iter-950 loss: 1.1130 validation: 0.978800
Iter-1000 loss: 1.2417 validation: 0.980800
Iter-1050 loss: 1.2190 validation: 0.981800
Iter-1100 loss: 1.1359 validation: 0.979600
Iter-1150 loss: 1.1761 validation: 0.980400
Iter-1200 loss: 1.2163 validation: 0.984400
Iter-1250 loss: 1.1531 validation: 0.984800
Iter-1300 loss: 1.1853 validation: 0.982200
Iter-1350 loss: 1.1644 validation: 0.985000
Iter-1400 loss: 1.1672 validation: 0.987400
Iter-1450 loss: 1.1757 validation: 0.987000
Iter-1500 loss: 1.1735 validation: 0.986800
Mean accuracy :0.9857,std :0.0000

Mean accuracy :0.9857,std :0.0000
6 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.0505 validation: 0.902800
Iter-50 loss: 1.0448 validation: 0.888000
Iter-50 loss: 1.3391 validation: 0.903200
Iter-50 loss: 1.3062 validation: 0.905400
Iter-100 loss: 1.2236 validation: 0.949800
Iter-100 loss: 1.3387 validation: 0.940400
Iter-100 loss: 1.1468 validation: 0.945600
Iter-100 loss: 1.1429 validation: 0.932200
Iter-150 loss: 1.2153 validation: 0.959400
Iter-150 loss: 1.0909 validation: 0.964000
Iter-150 loss: 1.1471 validation: 0.967600
Iter-150 loss: 1.0489 validation: 0.949000
Iter-200 loss: 1.0626 validation: 0.967800
Iter-200 loss: 1.0654 validation: 0.967600
Iter-200 loss: 1.0060 validation: 0.973000
Iter-200 loss: 0.9658 validation: 0.962000
Iter-250 loss: 1.1058 validation: 0.976200
Iter-250 loss: 1.0421 validation: 0.953800
Iter-250 loss: 1.0467 validation: 0.968800
Iter-250 loss: 1.0173 validation: 0.968400
Iter-300 loss: 1.3589 validation: 0.975400
Iter-300 loss: 1.1185 validation: 0.978600
Iter-300 loss: 1.0332 validation: 0.971600
Iter-300 loss: 1.1960 validation: 0.967600
Iter-350 loss: 1.0953 validation: 0.973400
Iter-350 loss: 1.0665 validation: 0.972000
Iter-350 loss: 1.0225 validation: 0.975200
Iter-350 loss: 1.0758 validation: 0.967800
Iter-400 loss: 1.1798 validation: 0.978800
Iter-400 loss: 1.0710 validation: 0.975400
Iter-400 loss: 1.0328 validation: 0.975600
Iter-400 loss: 1.0020 validation: 0.974600
Iter-450 loss: 1.1009 validation: 0.975000
Iter-450 loss: 1.0880 validation: 0.981000
Iter-450 loss: 1.1087 validation: 0.972200
Iter-450 loss: 1.0307 validation: 0.978000
Iter-500 loss: 1.1278 validation: 0.979800
Iter-500 loss: 1.0755 validation: 0.982400
Iter-500 loss: 1.0680 validation: 0.980200
Iter-500 loss: 1.0801 validation: 0.975400
Iter-550 loss: 1.0998 validation: 0.978600
Iter-550 loss: 1.1816 validation: 0.980800
Iter-550 loss: 1.0705 validation: 0.973400
Iter-550 loss: 1.0173 validation: 0.978200
Iter-600 loss: 1.1264 validation: 0.979200
Iter-600 loss: 1.1018 validation: 0.982000
Iter-600 loss: 1.1906 validation: 0.980600
Iter-600 loss: 1.0386 validation: 0.976800
Iter-650 loss: 1.1073 validation: 0.980800
Iter-650 loss: 1.0993 validation: 0.974800
Iter-650 loss: 1.0785 validation: 0.975200
Iter-650 loss: 1.0596 validation: 0.976200
Iter-700 loss: 1.1131 validation: 0.981600
Iter-700 loss: 1.0962 validation: 0.981600
Iter-700 loss: 1.0862 validation: 0.980200
Iter-700 loss: 1.0301 validation: 0.976600
Iter-750 loss: 1.1963 validation: 0.978600
Iter-750 loss: 1.1176 validation: 0.982400
Iter-750 loss: 1.1103 validation: 0.980800
Iter-750 loss: 1.0401 validation: 0.980800
Iter-800 loss: 1.1402 validation: 0.983000
Iter-800 loss: 1.1319 validation: 0.982600
Iter-800 loss: 1.0933 validation: 0.981200
Iter-800 loss: 1.0551 validation: 0.981000
Iter-850 loss: 1.1360 validation: 0.982600
Iter-850 loss: 1.1175 validation: 0.984600
Iter-850 loss: 1.2102 validation: 0.984000
Iter-850 loss: 1.0486 validation: 0.979000
Iter-900 loss: 1.1318 validation: 0.981800
Iter-900 loss: 1.2164 validation: 0.983400
Iter-900 loss: 1.1097 validation: 0.985000
Iter-900 loss: 1.1712 validation: 0.981400
Iter-950 loss: 1.1666 validation: 0.982800
Iter-950 loss: 1.1393 validation: 0.978200
Iter-950 loss: 1.1102 validation: 0.983200
Iter-950 loss: 1.0550 validation: 0.979800
Iter-1000 loss: 1.1449 validation: 0.984200
Iter-1000 loss: 1.1294 validation: 0.979200
Iter-1000 loss: 1.1586 validation: 0.982600
Iter-1000 loss: 1.0623 validation: 0.982000
Iter-1050 loss: 1.1477 validation: 0.983800
Iter-1050 loss: 1.1582 validation: 0.980400
Iter-1050 loss: 1.1238 validation: 0.982600
Iter-1050 loss: 1.0633 validation: 0.981400
Iter-1100 loss: 1.1514 validation: 0.982200
Iter-1100 loss: 1.1614 validation: 0.983600
Iter-1100 loss: 1.1252 validation: 0.981000
Iter-1100 loss: 1.0755 validation: 0.980400
Iter-1150 loss: 1.1563 validation: 0.983200
Iter-1150 loss: 1.1450 validation: 0.980400
Iter-1150 loss: 1.1285 validation: 0.981400
Iter-1150 loss: 1.0715 validation: 0.981800
Iter-1200 loss: 1.1589 validation: 0.982800
Iter-1200 loss: 1.1535 validation: 0.981400
Iter-1200 loss: 1.1392 validation: 0.982200
Iter-1200 loss: 1.1042 validation: 0.981400
Iter-1250 loss: 1.2166 validation: 0.981200
Iter-1250 loss: 1.1544 validation: 0.983400
Iter-1250 loss: 1.1420 validation: 0.980600
Iter-1250 loss: 1.0768 validation: 0.978200
Iter-1300 loss: 1.1655 validation: 0.981800
Iter-1300 loss: 1.1682 validation: 0.982400
Iter-1300 loss: 1.1489 validation: 0.981200
Iter-1300 loss: 1.1036 validation: 0.979400
Iter-1350 loss: 1.1661 validation: 0.984400
Iter-1350 loss: 1.1676 validation: 0.984600
Iter-1350 loss: 1.2049 validation: 0.983200
Iter-1350 loss: 1.0931 validation: 0.982600
Iter-1400 loss: 1.1689 validation: 0.984000
Iter-1400 loss: 1.1769 validation: 0.987600
Iter-1400 loss: 1.1530 validation: 0.982000
Iter-1400 loss: 1.1261 validation: 0.980600
Iter-1450 loss: 1.1699 validation: 0.984600
Iter-1450 loss: 1.1724 validation: 0.985600
Iter-1450 loss: 1.1533 validation: 0.982000
Iter-1450 loss: 1.0992 validation: 0.982800
Iter-1500 loss: 1.1934 validation: 0.981600
Iter-1500 loss: 1.1676 validation: 0.985400
Iter-1500 loss: 1.2755 validation: 0.981600
Iter-1500 loss: 1.1037 validation: 0.982200
Mean accuracy 1: 0.9833, std: 0.0000
Mean accuracy 2: 0.9836, std: 0.0000
Mean accuracy 3: 0.9814, std: 0.0000
Mean accuracy 4: 0.9846, std: 0.0000
Iter-50 loss: 1.2673 validation: 0.889800
Iter-100 loss: 1.0053 validation: 0.959400
Iter-150 loss: 1.1431 validation: 0.957600
Iter-200 loss: 1.1067 validation: 0.972600
Iter-250 loss: 1.0581 validation: 0.975800
Iter-300 loss: 1.1043 validation: 0.971400
Iter-350 loss: 1.0934 validation: 0.978000
Iter-400 loss: 1.0489 validation: 0.979800
Iter-450 loss: 1.0984 validation: 0.976400
Iter-500 loss: 1.1081 validation: 0.980800
Iter-550 loss: 1.0859 validation: 0.978200
Iter-600 loss: 1.0940 validation: 0.979800
Iter-650 loss: 1.1084 validation: 0.981800
Iter-700 loss: 1.1109 validation: 0.980800
Iter-750 loss: 1.2928 validation: 0.983200
Iter-800 loss: 1.1070 validation: 0.983200
Iter-850 loss: 1.1132 validation: 0.983000
Iter-900 loss: 1.1238 validation: 0.984000
Iter-950 loss: 1.1729 validation: 0.984800
Iter-1000 loss: 1.1531 validation: 0.984800
Iter-1050 loss: 1.1389 validation: 0.985400
Iter-1100 loss: 1.2094 validation: 0.981600
Iter-1150 loss: 1.1683 validation: 0.982600
Iter-1200 loss: 1.2034 validation: 0.984200
Iter-1250 loss: 1.1661 validation: 0.984000
Iter-1300 loss: 1.1892 validation: 0.984400
Iter-1350 loss: 1.1725 validation: 0.987000
Iter-1400 loss: 1.1745 validation: 0.985200
Iter-1450 loss: 1.1832 validation: 0.983200
Iter-1500 loss: 1.1825 validation: 0.985400
Mean accuracy :0.9847,std :0.0000

Mean accuracy :0.9847,std :0.0000
7 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.2881 validation: 0.888800
Iter-50 loss: 0.9472 validation: 0.907600
Iter-50 loss: 1.0647 validation: 0.908600
Iter-50 loss: 1.4157 validation: 0.877600
Iter-100 loss: 1.2766 validation: 0.957800
Iter-100 loss: 1.1063 validation: 0.957600
Iter-100 loss: 1.2186 validation: 0.957200
Iter-100 loss: 1.0855 validation: 0.937400
Iter-150 loss: 0.9819 validation: 0.962200
Iter-150 loss: 1.2419 validation: 0.941800
Iter-150 loss: 1.2048 validation: 0.967000
Iter-150 loss: 1.0906 validation: 0.947200
Iter-200 loss: 1.0310 validation: 0.939600
Iter-200 loss: 1.0217 validation: 0.966200
Iter-200 loss: 1.0359 validation: 0.972600
Iter-200 loss: 0.9814 validation: 0.964000
Iter-250 loss: 1.0070 validation: 0.971400
Iter-250 loss: 1.0526 validation: 0.958400
Iter-250 loss: 1.0990 validation: 0.970600
Iter-250 loss: 1.0180 validation: 0.968000
Iter-300 loss: 1.1069 validation: 0.975800
Iter-300 loss: 1.0567 validation: 0.977800
Iter-300 loss: 1.0243 validation: 0.973600
Iter-300 loss: 1.0185 validation: 0.966600
Iter-350 loss: 1.0586 validation: 0.974200
Iter-350 loss: 1.1872 validation: 0.973400
Iter-350 loss: 1.0849 validation: 0.973000
Iter-350 loss: 1.0981 validation: 0.971400
Iter-400 loss: 1.1117 validation: 0.977200
Iter-400 loss: 1.1822 validation: 0.974200
Iter-400 loss: 1.0379 validation: 0.970000
Iter-400 loss: 1.0225 validation: 0.974400
Iter-450 loss: 1.0568 validation: 0.979000
Iter-450 loss: 1.0458 validation: 0.972200
Iter-450 loss: 1.0591 validation: 0.974600
Iter-450 loss: 1.0368 validation: 0.971600
Iter-500 loss: 1.0535 validation: 0.979600
Iter-500 loss: 1.0458 validation: 0.977800
Iter-500 loss: 1.1041 validation: 0.980200
Iter-500 loss: 1.0933 validation: 0.975800
Iter-550 loss: 1.0569 validation: 0.970200
Iter-550 loss: 1.0528 validation: 0.979800
Iter-550 loss: 1.0819 validation: 0.962200
Iter-550 loss: 1.0741 validation: 0.977800
Iter-600 loss: 1.1139 validation: 0.976600
Iter-600 loss: 1.1372 validation: 0.976600
Iter-600 loss: 1.0794 validation: 0.981400
Iter-600 loss: 1.0807 validation: 0.975200
Iter-650 loss: 1.1180 validation: 0.977200
Iter-650 loss: 1.0825 validation: 0.981200
Iter-650 loss: 1.3613 validation: 0.973200
Iter-650 loss: 1.0566 validation: 0.976800
Iter-700 loss: 1.1144 validation: 0.977800
Iter-700 loss: 1.0775 validation: 0.976600
Iter-700 loss: 1.1765 validation: 0.978400
Iter-700 loss: 1.0745 validation: 0.955200
Iter-750 loss: 1.0933 validation: 0.984600
Iter-750 loss: 1.0955 validation: 0.979200
Iter-750 loss: 1.1045 validation: 0.982800
Iter-750 loss: 1.0738 validation: 0.974400
Iter-800 loss: 1.1880 validation: 0.980800
Iter-800 loss: 1.1177 validation: 0.982000
Iter-800 loss: 1.1085 validation: 0.980800
Iter-800 loss: 1.0862 validation: 0.978400
Iter-850 loss: 1.1051 validation: 0.979400
Iter-850 loss: 1.1450 validation: 0.979800
Iter-850 loss: 1.1155 validation: 0.975200
Iter-850 loss: 1.2913 validation: 0.979200
Iter-900 loss: 1.1210 validation: 0.982600
Iter-900 loss: 1.0960 validation: 0.982400
Iter-900 loss: 1.1142 validation: 0.978400
Iter-900 loss: 1.3221 validation: 0.978800
Iter-950 loss: 1.1280 validation: 0.982000
Iter-950 loss: 1.1084 validation: 0.982200
Iter-950 loss: 1.1315 validation: 0.983200
Iter-950 loss: 1.1052 validation: 0.976600
Iter-1000 loss: 1.1256 validation: 0.980000
Iter-1000 loss: 1.1125 validation: 0.983600
Iter-1000 loss: 1.1268 validation: 0.985400
Iter-1000 loss: 1.1128 validation: 0.976000
Iter-1050 loss: 1.1283 validation: 0.985000
Iter-1050 loss: 1.1640 validation: 0.982200
Iter-1050 loss: 1.1303 validation: 0.984400
Iter-1050 loss: 1.1188 validation: 0.971800
Iter-1100 loss: 1.1359 validation: 0.982600
Iter-1100 loss: 1.1223 validation: 0.980800
Iter-1100 loss: 1.1314 validation: 0.980800
Iter-1100 loss: 1.3445 validation: 0.979600
Iter-1150 loss: 1.1411 validation: 0.983200
Iter-1150 loss: 1.1972 validation: 0.983600
Iter-1150 loss: 1.1377 validation: 0.985200
Iter-1150 loss: 1.1520 validation: 0.979600
Iter-1200 loss: 1.1419 validation: 0.983800
Iter-1200 loss: 1.1767 validation: 0.983600
Iter-1200 loss: 1.4493 validation: 0.985000
Iter-1200 loss: 1.1444 validation: 0.982600
Iter-1250 loss: 1.1469 validation: 0.983600
Iter-1250 loss: 1.1340 validation: 0.982800
Iter-1250 loss: 1.1529 validation: 0.982800
Iter-1250 loss: 1.1436 validation: 0.980800
Iter-1300 loss: 1.1935 validation: 0.983200
Iter-1300 loss: 1.1345 validation: 0.985800
Iter-1300 loss: 1.1508 validation: 0.981800
Iter-1300 loss: 1.1479 validation: 0.981200
Iter-1350 loss: 1.1508 validation: 0.984600
Iter-1350 loss: 1.1410 validation: 0.983000
Iter-1350 loss: 1.1516 validation: 0.978800
Iter-1350 loss: 1.1541 validation: 0.981200
Iter-1400 loss: 1.1668 validation: 0.983800
Iter-1400 loss: 1.1398 validation: 0.986800
Iter-1400 loss: 1.1560 validation: 0.983200
Iter-1400 loss: 1.1616 validation: 0.983400
Iter-1450 loss: 1.1580 validation: 0.983600
Iter-1450 loss: 1.1404 validation: 0.986800
Iter-1450 loss: 1.1549 validation: 0.982600
Iter-1450 loss: 1.1620 validation: 0.979400
Iter-1500 loss: 1.1660 validation: 0.985000
Iter-1500 loss: 1.1574 validation: 0.985600
Iter-1500 loss: 1.1610 validation: 0.983200
Iter-1500 loss: 1.1647 validation: 0.983400
Mean accuracy 1: 0.9850, std: 0.0000
Mean accuracy 2: 0.9858, std: 0.0000
Mean accuracy 3: 0.9826, std: 0.0000
Mean accuracy 4: 0.9844, std: 0.0000
Iter-50 loss: 0.9744 validation: 0.885200
Iter-100 loss: 0.9305 validation: 0.936600
Iter-150 loss: 1.0418 validation: 0.959000
Iter-200 loss: 0.9930 validation: 0.964400
Iter-250 loss: 1.0368 validation: 0.966800
Iter-300 loss: 1.0734 validation: 0.976400
Iter-350 loss: 1.0945 validation: 0.981800
Iter-400 loss: 1.0482 validation: 0.975200
Iter-450 loss: 1.0645 validation: 0.977600
Iter-500 loss: 1.0433 validation: 0.977400
Iter-550 loss: 1.0619 validation: 0.980600
Iter-600 loss: 1.1655 validation: 0.977200
Iter-650 loss: 1.0989 validation: 0.979800
Iter-700 loss: 1.0819 validation: 0.972800
Iter-750 loss: 1.1263 validation: 0.972000
Iter-800 loss: 1.0994 validation: 0.981400
Iter-850 loss: 1.1041 validation: 0.979400
Iter-900 loss: 1.1089 validation: 0.981000
Iter-950 loss: 1.1151 validation: 0.980600
Iter-1000 loss: 1.1206 validation: 0.981800
Iter-1050 loss: 1.1388 validation: 0.982800
Iter-1100 loss: 1.1380 validation: 0.980000
Iter-1150 loss: 1.1331 validation: 0.982800
Iter-1200 loss: 1.1385 validation: 0.983800
Iter-1250 loss: 1.1431 validation: 0.983200
Iter-1300 loss: 1.1435 validation: 0.980400
Iter-1350 loss: 1.1465 validation: 0.981800
Iter-1400 loss: 1.1493 validation: 0.985200
Iter-1450 loss: 1.1688 validation: 0.981400
Iter-1500 loss: 1.1598 validation: 0.982400
Mean accuracy :0.9797,std :0.0000

Mean accuracy :0.9797,std :0.0000
8 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.2108 validation: 0.831400
Iter-50 loss: 1.2013 validation: 0.906800
Iter-50 loss: 1.0723 validation: 0.867200
Iter-50 loss: 1.4813 validation: 0.912600
Iter-100 loss: 1.3005 validation: 0.943200
Iter-100 loss: 1.0352 validation: 0.951200
Iter-100 loss: 1.2160 validation: 0.948200
Iter-100 loss: 1.0048 validation: 0.933800
Iter-150 loss: 1.0038 validation: 0.966000
Iter-150 loss: 1.2053 validation: 0.939800
Iter-150 loss: 1.0413 validation: 0.948400
Iter-150 loss: 1.3633 validation: 0.950200
Iter-200 loss: 0.9983 validation: 0.973600
Iter-200 loss: 1.0708 validation: 0.965600
Iter-200 loss: 1.1391 validation: 0.969000
Iter-200 loss: 1.0687 validation: 0.960400
Iter-250 loss: 1.0711 validation: 0.960000
Iter-250 loss: 1.0047 validation: 0.971200
Iter-250 loss: 1.0385 validation: 0.972400
Iter-250 loss: 1.0891 validation: 0.969000
Iter-300 loss: 1.0161 validation: 0.979600
Iter-300 loss: 1.0465 validation: 0.973600
Iter-300 loss: 1.0479 validation: 0.964800
Iter-300 loss: 1.1061 validation: 0.972000
Iter-350 loss: 1.0354 validation: 0.980000
Iter-350 loss: 1.0699 validation: 0.973600
Iter-350 loss: 1.0862 validation: 0.981200
Iter-350 loss: 1.0260 validation: 0.978600
Iter-400 loss: 1.0638 validation: 0.982200
Iter-400 loss: 1.0305 validation: 0.976200
Iter-400 loss: 1.0524 validation: 0.980600
Iter-400 loss: 1.1073 validation: 0.943000
Iter-450 loss: 1.0505 validation: 0.978600
Iter-450 loss: 1.0719 validation: 0.961200
Iter-450 loss: 1.0757 validation: 0.975800
Iter-450 loss: 1.0679 validation: 0.976800
Iter-500 loss: 1.1128 validation: 0.980800
Iter-500 loss: 1.0575 validation: 0.970200
Iter-500 loss: 1.1264 validation: 0.981600
Iter-500 loss: 1.0646 validation: 0.970400
Iter-550 loss: 1.1195 validation: 0.984000
Iter-550 loss: 1.1467 validation: 0.979200
Iter-550 loss: 1.1477 validation: 0.975600
Iter-550 loss: 1.0453 validation: 0.978800
Iter-600 loss: 1.0659 validation: 0.982800
Iter-600 loss: 1.1037 validation: 0.981000
Iter-600 loss: 1.0741 validation: 0.973600
Iter-600 loss: 1.2117 validation: 0.980200
Iter-650 loss: 1.0749 validation: 0.981400
Iter-650 loss: 1.1047 validation: 0.976200
Iter-650 loss: 1.1176 validation: 0.976000
Iter-650 loss: 1.0592 validation: 0.980800
Iter-700 loss: 1.0819 validation: 0.981000
Iter-700 loss: 1.0871 validation: 0.980200
Iter-700 loss: 1.1149 validation: 0.979600
Iter-700 loss: 1.0635 validation: 0.978200
Iter-750 loss: 1.1207 validation: 0.974000
Iter-750 loss: 1.1531 validation: 0.961800
Iter-750 loss: 1.1186 validation: 0.979000
Iter-750 loss: 1.0828 validation: 0.980200
Iter-800 loss: 1.1047 validation: 0.980000
Iter-800 loss: 1.1316 validation: 0.979600
Iter-800 loss: 1.1078 validation: 0.982800
Iter-800 loss: 1.0794 validation: 0.980800
Iter-850 loss: 1.1627 validation: 0.979600
Iter-850 loss: 1.1856 validation: 0.973400
Iter-850 loss: 1.1177 validation: 0.983400
Iter-850 loss: 1.1615 validation: 0.980400
Iter-900 loss: 1.1457 validation: 0.982400
Iter-900 loss: 1.1383 validation: 0.982800
Iter-900 loss: 1.1195 validation: 0.981600
Iter-900 loss: 1.0975 validation: 0.983400
Iter-950 loss: 1.1401 validation: 0.983200
Iter-950 loss: 1.1685 validation: 0.979400
Iter-950 loss: 1.1270 validation: 0.983600
Iter-950 loss: 1.1054 validation: 0.979400
Iter-1000 loss: 1.1380 validation: 0.982400
Iter-1000 loss: 1.1335 validation: 0.980400
Iter-1000 loss: 1.1403 validation: 0.978800
Iter-1000 loss: 1.0959 validation: 0.983600
Iter-1050 loss: 1.1589 validation: 0.983600
Iter-1050 loss: 1.1629 validation: 0.973600
Iter-1050 loss: 1.1376 validation: 0.983400
Iter-1050 loss: 1.1028 validation: 0.984400
Iter-1100 loss: 1.1440 validation: 0.981400
Iter-1100 loss: 1.1626 validation: 0.986000
Iter-1100 loss: 1.1415 validation: 0.984200
Iter-1100 loss: 1.1444 validation: 0.981800
Iter-1150 loss: 1.1452 validation: 0.978200
Iter-1150 loss: 1.1600 validation: 0.984800
Iter-1150 loss: 1.1445 validation: 0.983200
Iter-1150 loss: 1.1426 validation: 0.984200
Iter-1200 loss: 1.2106 validation: 0.984600
Iter-1200 loss: 1.1569 validation: 0.985400
Iter-1200 loss: 1.1472 validation: 0.986400
Iter-1200 loss: 1.1177 validation: 0.982200
Iter-1250 loss: 1.1554 validation: 0.986200
Iter-1250 loss: 1.1527 validation: 0.985600
Iter-1250 loss: 1.1521 validation: 0.983800
Iter-1250 loss: 1.1436 validation: 0.979000
Iter-1300 loss: 1.1605 validation: 0.984600
Iter-1300 loss: 1.1619 validation: 0.984200
Iter-1300 loss: 1.1546 validation: 0.980600
Iter-1300 loss: 1.1262 validation: 0.983000
Iter-1350 loss: 1.1731 validation: 0.986000
Iter-1350 loss: 1.1614 validation: 0.983800
Iter-1350 loss: 1.1585 validation: 0.981600
Iter-1350 loss: 1.1258 validation: 0.984200
Iter-1400 loss: 1.1665 validation: 0.986400
Iter-1400 loss: 1.1635 validation: 0.984800
Iter-1400 loss: 1.1605 validation: 0.983600
Iter-1400 loss: 1.1286 validation: 0.984400
Iter-1450 loss: 1.1672 validation: 0.984600
Iter-1450 loss: 1.1648 validation: 0.984600
Iter-1450 loss: 1.1963 validation: 0.983000
Iter-1450 loss: 1.1379 validation: 0.983400
Iter-1500 loss: 1.1690 validation: 0.984000
Iter-1500 loss: 1.1680 validation: 0.984200
Iter-1500 loss: 1.1635 validation: 0.983000
Iter-1500 loss: 1.1380 validation: 0.984200
Mean accuracy 1: 0.9828, std: 0.0000
Mean accuracy 2: 0.9829, std: 0.0000
Mean accuracy 3: 0.9838, std: 0.0000
Mean accuracy 4: 0.9848, std: 0.0000
Iter-50 loss: 0.9755 validation: 0.933800
Iter-100 loss: 1.0356 validation: 0.927400
Iter-150 loss: 1.0180 validation: 0.955200
Iter-200 loss: 1.0477 validation: 0.965400
Iter-250 loss: 1.0084 validation: 0.970600
Iter-300 loss: 1.1519 validation: 0.927000
Iter-350 loss: 1.0822 validation: 0.972200
Iter-400 loss: 1.2454 validation: 0.971000
Iter-450 loss: 1.1727 validation: 0.976600
Iter-500 loss: 1.0759 validation: 0.977000
Iter-550 loss: 1.1782 validation: 0.976800
Iter-600 loss: 1.1433 validation: 0.978200
Iter-650 loss: 1.1204 validation: 0.973400
Iter-700 loss: 1.1088 validation: 0.982400
Iter-750 loss: 1.1150 validation: 0.979000
Iter-800 loss: 1.1512 validation: 0.979400
Iter-850 loss: 1.1266 validation: 0.981800
Iter-900 loss: 1.1318 validation: 0.982800
Iter-950 loss: 1.1340 validation: 0.984400
Iter-1000 loss: 1.2597 validation: 0.984600
Iter-1050 loss: 1.1439 validation: 0.980400
Iter-1100 loss: 1.1632 validation: 0.980000
Iter-1150 loss: 1.1563 validation: 0.981000
Iter-1200 loss: 1.2309 validation: 0.982800
Iter-1250 loss: 1.1765 validation: 0.982600
Iter-1300 loss: 1.2220 validation: 0.982400
Iter-1350 loss: 1.1630 validation: 0.982200
Iter-1400 loss: 1.1675 validation: 0.983800
Iter-1450 loss: 1.1857 validation: 0.983800
Iter-1500 loss: 1.1732 validation: 0.983400
Mean accuracy :0.9833,std :0.0000

Mean accuracy :0.9833,std :0.0000
9 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.1770 validation: 0.850000
Iter-50 loss: 1.1095 validation: 0.873800
Iter-50 loss: 1.0742 validation: 0.890000
Iter-50 loss: 1.0970 validation: 0.887400
Iter-100 loss: 1.1577 validation: 0.955400
Iter-100 loss: 1.0736 validation: 0.951400
Iter-100 loss: 1.0473 validation: 0.934200
Iter-100 loss: 0.9870 validation: 0.937400
Iter-150 loss: 1.0015 validation: 0.968600
Iter-150 loss: 0.9908 validation: 0.969200
Iter-150 loss: 0.9896 validation: 0.963800
Iter-150 loss: 1.0742 validation: 0.963600
Iter-200 loss: 1.2367 validation: 0.958200
Iter-200 loss: 1.0465 validation: 0.967200
Iter-200 loss: 1.0297 validation: 0.966200
Iter-200 loss: 0.9981 validation: 0.972800
Iter-250 loss: 1.0279 validation: 0.970000
Iter-250 loss: 1.0456 validation: 0.969600
Iter-250 loss: 1.0635 validation: 0.970800
Iter-250 loss: 1.0088 validation: 0.970200
Iter-300 loss: 1.0402 validation: 0.973000
Iter-300 loss: 1.0555 validation: 0.972400
Iter-300 loss: 1.0497 validation: 0.972600
Iter-300 loss: 1.0074 validation: 0.969600
Iter-350 loss: 1.1921 validation: 0.976600
Iter-350 loss: 1.0315 validation: 0.967800
Iter-350 loss: 1.0652 validation: 0.965200
Iter-350 loss: 1.0606 validation: 0.974000
Iter-400 loss: 1.1303 validation: 0.972400
Iter-400 loss: 1.0808 validation: 0.979200
Iter-400 loss: 1.0901 validation: 0.975400
Iter-400 loss: 1.1406 validation: 0.974400
Iter-450 loss: 1.0772 validation: 0.982000
Iter-450 loss: 1.1238 validation: 0.969400
Iter-450 loss: 1.0721 validation: 0.966600
Iter-450 loss: 1.0343 validation: 0.976000
Iter-500 loss: 1.0653 validation: 0.984200
Iter-500 loss: 1.0590 validation: 0.981200
Iter-500 loss: 1.1862 validation: 0.973800
Iter-500 loss: 1.0500 validation: 0.977800
Iter-550 loss: 1.1500 validation: 0.982600
Iter-550 loss: 1.0679 validation: 0.981200
Iter-550 loss: 1.0816 validation: 0.979800
Iter-550 loss: 1.0679 validation: 0.974600
Iter-600 loss: 1.0894 validation: 0.979200
Iter-600 loss: 1.1204 validation: 0.980800
Iter-600 loss: 1.0974 validation: 0.978000
Iter-600 loss: 1.0820 validation: 0.980400
Iter-650 loss: 1.0902 validation: 0.985000
Iter-650 loss: 1.0981 validation: 0.979800
Iter-650 loss: 1.1207 validation: 0.975000
Iter-650 loss: 1.0682 validation: 0.977000
Iter-700 loss: 1.1196 validation: 0.981000
Iter-700 loss: 1.1227 validation: 0.974800
Iter-700 loss: 1.1033 validation: 0.981800
Iter-700 loss: 1.0801 validation: 0.978000
Iter-750 loss: 1.0998 validation: 0.982200
Iter-750 loss: 1.1449 validation: 0.981400
Iter-750 loss: 1.1029 validation: 0.977200
Iter-750 loss: 1.0889 validation: 0.984000
Iter-800 loss: 1.1149 validation: 0.981400
Iter-800 loss: 1.1174 validation: 0.982200
Iter-800 loss: 1.1214 validation: 0.981600
Iter-800 loss: 1.1519 validation: 0.982000
Iter-850 loss: 1.1097 validation: 0.982000
Iter-850 loss: 1.1097 validation: 0.980800
Iter-850 loss: 1.1165 validation: 0.980000
Iter-850 loss: 1.1042 validation: 0.981800
Iter-900 loss: 1.1143 validation: 0.983400
Iter-900 loss: 1.1287 validation: 0.985000
Iter-900 loss: 1.1240 validation: 0.983200
Iter-900 loss: 1.1037 validation: 0.981400
Iter-950 loss: 1.1328 validation: 0.984600
Iter-950 loss: 1.1364 validation: 0.986600
Iter-950 loss: 1.1407 validation: 0.981800
Iter-950 loss: 1.1275 validation: 0.980400
Iter-1000 loss: 1.1253 validation: 0.984600
Iter-1000 loss: 1.1300 validation: 0.981600
Iter-1000 loss: 1.3661 validation: 0.983800
Iter-1000 loss: 1.1175 validation: 0.982600
Iter-1050 loss: 1.1344 validation: 0.981800
Iter-1050 loss: 1.1336 validation: 0.981200
Iter-1050 loss: 1.1370 validation: 0.983000
Iter-1050 loss: 1.1199 validation: 0.984000
Iter-1100 loss: 1.1794 validation: 0.983400
Iter-1100 loss: 1.1329 validation: 0.983600
Iter-1100 loss: 1.1617 validation: 0.979800
Iter-1100 loss: 1.1238 validation: 0.979200
Iter-1150 loss: 1.1385 validation: 0.986800
Iter-1150 loss: 1.1322 validation: 0.983000
Iter-1150 loss: 1.1398 validation: 0.980800
Iter-1150 loss: 1.1268 validation: 0.980600
Iter-1200 loss: 1.1415 validation: 0.986800
Iter-1200 loss: 1.1441 validation: 0.984400
Iter-1200 loss: 1.1898 validation: 0.982800
Iter-1200 loss: 1.1297 validation: 0.982600
Iter-1250 loss: 1.1498 validation: 0.987200
Iter-1250 loss: 1.1492 validation: 0.982800
Iter-1250 loss: 1.1525 validation: 0.983600
Iter-1250 loss: 1.1342 validation: 0.982800
Iter-1300 loss: 1.1508 validation: 0.982600
Iter-1300 loss: 1.1426 validation: 0.983800
Iter-1300 loss: 1.1445 validation: 0.983000
Iter-1300 loss: 1.1604 validation: 0.980000
Iter-1350 loss: 1.1529 validation: 0.983200
Iter-1350 loss: 1.1473 validation: 0.985200
Iter-1350 loss: 1.1490 validation: 0.979200
Iter-1350 loss: 1.1497 validation: 0.984000
Iter-1400 loss: 1.1621 validation: 0.985400
Iter-1400 loss: 1.1449 validation: 0.984800
Iter-1400 loss: 1.1553 validation: 0.983800
Iter-1400 loss: 1.1474 validation: 0.986000
Iter-1450 loss: 1.1596 validation: 0.985800
Iter-1450 loss: 1.1451 validation: 0.984400
Iter-1450 loss: 1.1558 validation: 0.979200
Iter-1450 loss: 1.1497 validation: 0.984600
Iter-1500 loss: 1.1575 validation: 0.987200
Iter-1500 loss: 1.1483 validation: 0.985200
Iter-1500 loss: 1.1655 validation: 0.984600
Iter-1500 loss: 1.1539 validation: 0.985800
Mean accuracy 1: 0.9838, std: 0.0000
Mean accuracy 2: 0.9845, std: 0.0000
Mean accuracy 3: 0.9851, std: 0.0000
Mean accuracy 4: 0.9856, std: 0.0000
Iter-50 loss: 1.1097 validation: 0.903800
Iter-100 loss: 1.0776 validation: 0.963400
Iter-150 loss: 1.0971 validation: 0.957800
Iter-200 loss: 1.0949 validation: 0.975400
Iter-250 loss: 1.0026 validation: 0.975200
Iter-300 loss: 0.9934 validation: 0.961400
Iter-350 loss: 1.0329 validation: 0.975600
Iter-400 loss: 1.1541 validation: 0.974400
Iter-450 loss: 1.1025 validation: 0.977200
Iter-500 loss: 1.0671 validation: 0.981800
Iter-550 loss: 1.0386 validation: 0.980000
Iter-600 loss: 1.0587 validation: 0.969000
Iter-650 loss: 1.0557 validation: 0.982800
Iter-700 loss: 1.0731 validation: 0.983000
Iter-750 loss: 1.0909 validation: 0.974800
Iter-800 loss: 1.0849 validation: 0.977000
Iter-850 loss: 1.1129 validation: 0.977600
Iter-900 loss: 1.1146 validation: 0.978000
Iter-950 loss: 1.1051 validation: 0.984400
Iter-1000 loss: 1.1175 validation: 0.985200
Iter-1050 loss: 1.1069 validation: 0.983200
Iter-1100 loss: 1.1108 validation: 0.982800
Iter-1150 loss: 1.1235 validation: 0.984600
Iter-1200 loss: 1.1224 validation: 0.982800
Iter-1250 loss: 1.1290 validation: 0.982800
Iter-1300 loss: 1.1385 validation: 0.985000
Iter-1350 loss: 1.1926 validation: 0.984200
Iter-1400 loss: 1.1311 validation: 0.984600
Iter-1450 loss: 1.1319 validation: 0.983000
Iter-1500 loss: 1.1364 validation: 0.984600
Mean accuracy :0.9831,std :0.0000

Mean accuracy :0.9831,std :0.0000
10 epoch
/home/wzd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /home/wzd/桌面/deepchain2/deepchain/deepchain/hipsternet/split_mnist.py:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/wzd/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Extracting MNIST_Data/train-images-idx3-ubyte.gz
Extracting MNIST_Data/train-labels-idx1-ubyte.gz
Extracting MNIST_Data/t10k-images-idx3-ubyte.gz
Extracting MNIST_Data/t10k-labels-idx1-ubyte.gz
Extracting ./MNIST_data/train-images-idx3-ubyte.gz
Extracting ./MNIST_data/train-labels-idx1-ubyte.gz
Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz
(13750, 784)
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750,)
M 13750 D 784 C 10 
(13750, 1, 28, 28)

Experimenting on sgd3

Experiment-1
Iter-50 loss: 1.1731 validation: 0.779400
Iter-50 loss: 1.4339 validation: 0.813600
Iter-50 loss: 1.3218 validation: 0.893000
Iter-50 loss: 1.1985 validation: 0.933800
Iter-100 loss: 0.9723 validation: 0.967000
Iter-100 loss: 1.1503 validation: 0.939600
Iter-100 loss: 1.0541 validation: 0.959400
Iter-100 loss: 1.0185 validation: 0.943800
Iter-150 loss: 1.0303 validation: 0.967400
Iter-150 loss: 1.0760 validation: 0.965800
Iter-150 loss: 1.0242 validation: 0.959200
Iter-150 loss: 1.0186 validation: 0.948200
Iter-200 loss: 0.9856 validation: 0.973600
Iter-200 loss: 1.0623 validation: 0.963200
Iter-200 loss: 1.0175 validation: 0.972200
Iter-200 loss: 1.1419 validation: 0.968400
Iter-250 loss: 1.0252 validation: 0.970200
Iter-250 loss: 1.0206 validation: 0.975000
Iter-250 loss: 1.0147 validation: 0.972600
Iter-250 loss: 1.0231 validation: 0.965600
Iter-300 loss: 1.0704 validation: 0.976600
Iter-300 loss: 1.0726 validation: 0.973200
Iter-300 loss: 1.0122 validation: 0.940800
Iter-300 loss: 1.0296 validation: 0.968400
Iter-350 loss: 1.2756 validation: 0.970600
Iter-350 loss: 1.0409 validation: 0.977400
Iter-350 loss: 1.0444 validation: 0.971400
Iter-350 loss: 1.0324 validation: 0.970200
Iter-400 loss: 1.0549 validation: 0.978400
Iter-400 loss: 1.0722 validation: 0.974600
Iter-400 loss: 1.0352 validation: 0.976800
Iter-400 loss: 1.0409 validation: 0.972400
Iter-450 loss: 1.1940 validation: 0.974400
Iter-450 loss: 1.0615 validation: 0.978800
Iter-450 loss: 1.1000 validation: 0.975400
Iter-450 loss: 1.0462 validation: 0.966000
Iter-500 loss: 1.0761 validation: 0.972400
Iter-500 loss: 1.0653 validation: 0.976200
Iter-500 loss: 1.0791 validation: 0.972000
Iter-500 loss: 1.1469 validation: 0.978800
Iter-550 loss: 1.0710 validation: 0.984200
Iter-550 loss: 1.0935 validation: 0.980200
Iter-550 loss: 1.0910 validation: 0.977200
Iter-550 loss: 1.1066 validation: 0.977800
Iter-600 loss: 1.0822 validation: 0.976400
Iter-600 loss: 1.1144 validation: 0.976600
Iter-600 loss: 1.0874 validation: 0.964200
Iter-600 loss: 1.0687 validation: 0.972800
Iter-650 loss: 1.1094 validation: 0.977000
Iter-650 loss: 1.0929 validation: 0.975200
Iter-650 loss: 1.0831 validation: 0.979200
Iter-650 loss: 1.0750 validation: 0.969800
Iter-700 loss: 1.1476 validation: 0.981400
Iter-700 loss: 1.1086 validation: 0.973600
Iter-700 loss: 1.0847 validation: 0.974800
Iter-700 loss: 1.1221 validation: 0.978000
Iter-750 loss: 1.0971 validation: 0.984600
Iter-750 loss: 1.0999 validation: 0.982800
Iter-750 loss: 1.1069 validation: 0.978800
Iter-750 loss: 1.1216 validation: 0.976600
Iter-800 loss: 1.1282 validation: 0.983800
Iter-800 loss: 1.1000 validation: 0.979800
Iter-800 loss: 1.1016 validation: 0.982400
Iter-800 loss: 1.0956 validation: 0.981400
Iter-850 loss: 1.1083 validation: 0.984200
Iter-850 loss: 1.1062 validation: 0.980400
Iter-850 loss: 1.1152 validation: 0.976200
Iter-850 loss: 1.1056 validation: 0.980000
Iter-900 loss: 1.2347 validation: 0.982200
Iter-900 loss: 1.1829 validation: 0.979800
Iter-900 loss: 1.1173 validation: 0.980200
Iter-900 loss: 1.1056 validation: 0.981400
Iter-950 loss: 1.1502 validation: 0.984600
Iter-950 loss: 1.1245 validation: 0.980400
Iter-950 loss: 1.1191 validation: 0.980000
Iter-950 loss: 1.1046 validation: 0.978600
Iter-1000 loss: 1.1246 validation: 0.983600
Iter-1000 loss: 1.1285 validation: 0.980000
Iter-1000 loss: 1.1296 validation: 0.976200
Iter-1000 loss: 1.1890 validation: 0.981200
Iter-1050 loss: 1.1265 validation: 0.987400
Iter-1050 loss: 1.1358 validation: 0.982400
Iter-1050 loss: 1.1340 validation: 0.980600
Iter-1050 loss: 1.1098 validation: 0.979200
Iter-1100 loss: 1.1350 validation: 0.985400
Iter-1100 loss: 1.1957 validation: 0.979400
Iter-1100 loss: 1.1383 validation: 0.980600
Iter-1100 loss: 1.1118 validation: 0.975800
Iter-1150 loss: 1.1310 validation: 0.986400
Iter-1150 loss: 1.1480 validation: 0.980800
Iter-1150 loss: 1.1430 validation: 0.978800
Iter-1150 loss: 1.1178 validation: 0.981000
Iter-1200 loss: 1.1358 validation: 0.984200
Iter-1200 loss: 1.1562 validation: 0.984200
Iter-1200 loss: 1.1550 validation: 0.975000
Iter-1200 loss: 1.1204 validation: 0.981400
Iter-1250 loss: 1.1384 validation: 0.984000
Iter-1250 loss: 1.1477 validation: 0.984600
Iter-1250 loss: 1.1764 validation: 0.980400
Iter-1250 loss: 1.1200 validation: 0.982000
Iter-1300 loss: 1.1412 validation: 0.985400
Iter-1300 loss: 1.1556 validation: 0.982400
Iter-1300 loss: 1.1637 validation: 0.978600
Iter-1300 loss: 1.1350 validation: 0.980400
Iter-1350 loss: 1.1446 validation: 0.987000
Iter-1350 loss: 1.1505 validation: 0.981800
Iter-1350 loss: 1.1604 validation: 0.982000
Iter-1350 loss: 1.1739 validation: 0.979400
Iter-1400 loss: 1.1473 validation: 0.987000
Iter-1400 loss: 1.1562 validation: 0.984800
Iter-1400 loss: 1.1618 validation: 0.983200
Iter-1400 loss: 1.1312 validation: 0.981600
Iter-1450 loss: 1.1493 validation: 0.985200
Iter-1450 loss: 1.1559 validation: 0.984600
Iter-1450 loss: 1.1864 validation: 0.982800
Iter-1450 loss: 1.1335 validation: 0.983200
Iter-1500 loss: 1.1524 validation: 0.986600
Iter-1500 loss: 1.1602 validation: 0.984400
Iter-1500 loss: 1.1966 validation: 0.981400
Iter-1500 loss: 1.1361 validation: 0.984000
Mean accuracy 1: 0.9869, std: 0.0000
Mean accuracy 2: 0.9864, std: 0.0000
Mean accuracy 3: 0.9821, std: 0.0000
Mean accuracy 4: 0.9851, std: 0.0000
Iter-50 loss: 1.5368 validation: 0.867200
Iter-100 loss: 1.0574 validation: 0.920800
Iter-150 loss: 0.9958 validation: 0.968400
Iter-200 loss: 1.0439 validation: 0.971800
Iter-250 loss: 1.0015 validation: 0.976800
Iter-300 loss: 1.0309 validation: 0.972200
Iter-350 loss: 1.3032 validation: 0.978600
Iter-400 loss: 1.0661 validation: 0.981400
Iter-450 loss: 1.0495 validation: 0.981400
Iter-500 loss: 1.0709 validation: 0.981800
Iter-550 loss: 1.1318 validation: 0.974000
Iter-600 loss: 1.0885 validation: 0.982400
Iter-650 loss: 1.0880 validation: 0.983400
Iter-700 loss: 1.0872 validation: 0.986200
Iter-750 loss: 1.1032 validation: 0.978200
Iter-800 loss: 1.1608 validation: 0.982800
Iter-850 loss: 1.1494 validation: 0.980400
Iter-900 loss: 1.1208 validation: 0.982200
Iter-950 loss: 1.1235 validation: 0.983600
Iter-1000 loss: 1.1193 validation: 0.983000
Iter-1050 loss: 1.1230 validation: 0.986000
Iter-1100 loss: 1.2575 validation: 0.985800
Iter-1150 loss: 1.1320 validation: 0.982000
Iter-1200 loss: 1.1522 validation: 0.984200
Iter-1250 loss: 1.1447 validation: 0.984400
Iter-1300 loss: 1.1482 validation: 0.984800
Iter-1350 loss: 1.1444 validation: 0.986000
Iter-1400 loss: 1.1477 validation: 0.985400
Iter-1450 loss: 1.1488 validation: 0.986200
Iter-1500 loss: 1.1504 validation: 0.986800
Mean accuracy :0.9862,std :0.0000

Mean accuracy :0.9862,std :0.0000

